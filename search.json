[
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "💬 Talks",
    "section": "",
    "text": "Talks I’ve given over the years.\n\n\n\n\n\n\n\n\n  \n\n\n\n\nCode represents the ideas of people\n\n\n\n\n\n\n\n\n\n\nBy considering the people who use our code, we minimize the cost of translating from obscure machine-friendly commands into beautiful prose, thus freeing our minds to focus on what’s really important: the ideas themselves.\n\n\n\n\n\n\nMar 17, 2018\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/code-represents-the-ideas-of-people.html",
    "href": "talks/code-represents-the-ideas-of-people.html",
    "title": "Code represents the ideas of people",
    "section": "",
    "text": "(The original title and description of the talk changed between the pitch and final version, hence the differences.)\nThis is a lightning talk I gave at the satRday 2018 conference. In it, I share an epiphany I had about programming and how it relates to people and our ideas, after programming for most of my life and discovering higher-level languages like Python and R. The talk won best student lightning talk, which included a copy of the beautiful R for Data Science signed by Hadley Wickham himself!\nFast forward 4 years, and this realisation doesn’t feel as profound as it once did, but that’s okay. I believe the world would be a little better if everyone shared their personal learnings and experiences. Please let me know of yours!\nAnyway, keep scrolling for a written version of the talk."
  },
  {
    "objectID": "talks/code-represents-the-ideas-of-people.html#my-journey-from-game-maker-to-python",
    "href": "talks/code-represents-the-ideas-of-people.html#my-journey-from-game-maker-to-python",
    "title": "Code represents the ideas of people",
    "section": "My journey from Game Maker to Python ",
    "text": "My journey from Game Maker to Python \n\n\n\n\n\nGood morning everyone, my name is Wasim.\nA little background. I started programming when I was in primary school. I’ve always loved games, and making things. Unsurprisingly, my foray into programming started with making games.\nAfter vigorous searching for game making software, with my favourite search engine at the time, AltaVista, which some of you may remember, I found a program called Game Maker.\nIt had a GUI, where you created game objects and programmed logic into them with buttons. It also had scripting capabilities. But I didn’t dare to delve into them.\n\n\n\n\n\nEventually, a cousin of mine introduced me to a more powerful tool. A programming language called DarkBASIC, a form of the language, BASIC.\nIt had a nice editor, a built-in command line interface. I think the 1 and 2 on the top right corresponded to tabs. And it allowed you to create 3D games.\n\n\n\n\n\nI then moved on to some of the more “real” programming languages. I dabbled in C++.\nI was taught Java in high school.\nAnd finally, I settled on Python. I think the reason I hopped so often from one language to the next, was because I was never quite satisfied with how it “felt” to program in these languages. I was never truly comfortable with the way I had to translate what I thought into what I typed. Until Python."
  },
  {
    "objectID": "talks/code-represents-the-ideas-of-people.html#the-joy-of-high-level-languages",
    "href": "talks/code-represents-the-ideas-of-people.html#the-joy-of-high-level-languages",
    "title": "Code represents the ideas of people",
    "section": "The joy of high-level languages ",
    "text": "The joy of high-level languages \n\n\n\n\n\nWith Python, I learned about writing and reading beautiful code. If you haven’t already seen this poem, The Zen of Python, by Tim Peters, you should check it out.\nThere is an idea called writing “Pythonic” code, which this poem sort of defines. There was something compelling, almost poetic, about reading and writing “Pythonic” code.\nAs a young programmer, it was the first time I realized the importance of how code looks, not just what it does."
  },
  {
    "objectID": "talks/code-represents-the-ideas-of-people.html#this-is-not-a-pipe",
    "href": "talks/code-represents-the-ideas-of-people.html#this-is-not-a-pipe",
    "title": "Code represents the ideas of people",
    "section": "This is not a pipe ",
    "text": "This is not a pipe \n\n\n\n\n\nMore recently, I came across an even more interesting idea about how code looks.\nHere’s a painting, by the French artist, René Magritte, that captures the idea. The text at the bottom translates to “This is not a pipe.”\nIf you haven’t seen this before, that might be a little confusing.\n“That is a pipe. I’ve seen pipes before, and that, my friend, is a pipe.”\nWell, you can’t pack this with tobacco and smoke it. This is a painting of a pipe, an image, a representation, but its not the pipe itself.\nAt this point, you might be wondering: What does this have to do with code? And what does this talk have to do with R?\nWell, just as this is a representation of a pipe…"
  },
  {
    "objectID": "talks/code-represents-the-ideas-of-people.html#this-is-not-an-idea",
    "href": "talks/code-represents-the-ideas-of-people.html#this-is-not-an-idea",
    "title": "Code represents the ideas of people",
    "section": "This is not an idea ",
    "text": "This is not an idea \n\n\n\n\n\nThis is a representation of an idea. The code is not the idea itself.\nI believe that when we code (even for experts) we constantly struggle translating between our idea and its representation. If the code is a particularly good representation of our underlying idea, then it flows seamlessly, almost by itself.\nOn the other hand, if the code is not a good representation of our idea, then this struggle is quite costly.\nI wanna show you, by example, why I’m so fascinated by R. This is some very simple dplyr code.\nWhat I do when I read (or write) code like this, is to translate it to and from English. I don’t think “df percent greater than percent…”"
  },
  {
    "objectID": "talks/code-represents-the-ideas-of-people.html#translating-code-to-idea",
    "href": "talks/code-represents-the-ideas-of-people.html#translating-code-to-idea",
    "title": "Code represents the ideas of people",
    "section": "Translating code to idea ",
    "text": "Translating code to idea \n\nI might start off by thinking that I want to “Take df”, in order to do something to it.\nI’d read the pipe symbol %>% as “then”.\nI then want to filter “rows of df where”\nRead the symbol as “is less than”\nReplace the pipe symbol with “then” again\nI then want to arrange rows of df by…\nSame thing with the pipe symbol.\nAnd finally, I want to select the column…\nAnd, very easily, we have an English sentence.\nOh! And if we’re really fussy, we could add punctuation.\nSo we’ve translated, very easily and systematically, from dplyr code to English.\nIsn’t that a beautiful representation?\nIt’s beautiful because it’s been so carefully designed, functions have been so carefully named, all keeping in mind one very important principle:"
  },
  {
    "objectID": "talks/code-represents-the-ideas-of-people.html#code-represents-the-ideas-of-people",
    "href": "talks/code-represents-the-ideas-of-people.html#code-represents-the-ideas-of-people",
    "title": "Code represents the ideas of people",
    "section": "Code represents the ideas of people ",
    "text": "Code represents the ideas of people \n\n\n\n\n\nCode represents the ideas of people. By considering the people who will use it, we minimize the cost of translating from obscure machine-friendly commands into beautiful prose.\nAnd by minimizing this cost, it frees our minds to focus on what’s really important: the ideas themselves."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "👋🏽 Hi, I’m Wasim",
    "section": "",
    "text": "I’m a machine learning engineer and aspiring entrepreneur.\nThis is where I write about what I’m working on, which includes notebook-driven development, artificial intelligence, software design, programming languages, and other musings.\nYou might also want to check out my full list of projects, talks, and TILs (today I learneds).\nPreviously, I held technical leadership positions in South African AI startups in manufacturing and agriculture. Before that, I was a professional DotA 2 player.\n\n\nDo you use nbdev for notebook-driven development and need it adapted to your business needs? Do you need support architecting and building machine learning systems? Do you need to implement a novel deep learning technique customized to your use-case?\nI’m open to consulting or contract work on a per-project basis. If you’d like to get in touch, please DM me on Twitter or email me at mwlorgat@gmail.com and let’s chat!\n\n\n\nMastodon verification"
  },
  {
    "objectID": "posts/fastai-array-programming-day-1.html",
    "href": "posts/fastai-array-programming-day-1.html",
    "title": "fast.ai APL study group: Day 1",
    "section": "",
    "text": "Here are my notes for day 1 of the FastAI array programming study group run by Jeremy Howard. Check out the official thread on the FastAI forum for up-to-date info. Any mistakes are mine - please let me know if you spot one."
  },
  {
    "objectID": "posts/fastai-array-programming-day-1.html#why-learn-apl",
    "href": "posts/fastai-array-programming-day-1.html#why-learn-apl",
    "title": "fast.ai APL study group: Day 1",
    "section": "Why learn APL?",
    "text": "Why learn APL?\n[Jeremy gave a personal answer here. I’ve paraphrased here and there, and reframed it in the third person, hopefully without changing his intended meaning.]\n\nAPL is a way into learning and teaching math\nMath is beautiful… but also very frustrating. It’s inconsistent, the notation is hard to lookup, and it’s hard to understand what things mean in a very abstract way when we can’t experiment with them. APL helps us understand math, thus it helps us teach math.\nJeremy teaches his daughter and her friend math. He found that there were concepts that he found very difficult to teach in traditional abstract ways. In particular, he spent an hour trying to teach them sequences and series with very little progress. He then tried it again with numpy and APL and it clicked much more easily.\n\n\nThere’s emmense beauty and power in notations\nIn a previous live coding session, Jeremy talked about regex being a powerful notation. Powerful notations are key to furthering human intellectual development. You see this repeatedly in many domains, particularly math and physics. New ideas take hundreds of years to figure out become far simpler once someone finds the right notation. Notations grant us the ability to manipulate symbols to develop new ideas. Examples include algebra, zero, and even juggling!\nAPL is a very powerful notation, not just for math but for a range of topics that use similar concepts as math. For example, Aaron Hsu’s PhD used APL to build a compiler on the GPU.\n\n\nAPL will challenge you to think about programming in new ways\nAPL is an independently developed branch of programming with a rich history. APL as a notation has been developed since the 1960s, largely independently to other branches of programming languages. If you never learn about it, you miss out on an entire branch of languages with an incredibly rich history. Jeremy felt that learning array programming did more for his programming skills than any other language he’s learned."
  },
  {
    "objectID": "posts/fastai-array-programming-day-1.html#setting-up-dyalog-in-jupyter",
    "href": "posts/fastai-array-programming-day-1.html#setting-up-dyalog-in-jupyter",
    "title": "fast.ai APL study group: Day 1",
    "section": "Setting up Dyalog in Jupyter",
    "text": "Setting up Dyalog in Jupyter\n\nInstall Dyalog\nWe’ll use Dyalog, an APL dialect. The first step is to install Dyalog from their download page.\n\n\nInstall the Dyalog Jupyter kernel\nAlthough Dyalog comes with an IDE, we’ll use Jupyter notebooks. Make sure that you’ve installed Jupyter notebook. Then install Dyalog Jupyter kernel following their installation instructions. Although their instructions say that Anaconda is required, I didn’t need it on MacOS.\n\n\nCreate a notebook with the Dyalog kernel\nClick New, then Dyalog APL.\n\n\n\nCreate a Dyalog notebook in Jupyter by clicking New then Dyalog APL.|Create a Dyalog notebook in Jupyter by clicking New then Dyalog APL.\n\n\nYou should now be able to write Dyalog directly in your notebook! Try it out:\n\n1 2 3 - 4 5 6\n\n¯3 ¯3 ¯3\n\n\n\n\n\nTips for a smoother dev environment\nAPL uses a variety of glyphs like the ¯ glyph in the previous output. To make these easier to type in your notebook, you might want to use the APL language bar. It lets you use backtick (`) as a prefix to enter glyphs. For example, <backtick>2 is a shortcut for the ¯ glyph. You can type <backtick><space> to enter a normal backtick again. It also adds a bar to the top of the page with all of the possible glyphs:\n\n\n\nThe APL langauge bar: a horizontal list of APL gylphs.\n\n\nHovering on a glyph shows a its name and keyboard shortucts:\n\n\n\nHovering on the minus sign glyph shows ‘negate minus’."
  },
  {
    "objectID": "posts/fastai-array-programming-day-1.html#a-top-down-learning-plan",
    "href": "posts/fastai-array-programming-day-1.html#a-top-down-learning-plan",
    "title": "fast.ai APL study group: Day 1",
    "section": "A top-down learning plan",
    "text": "A top-down learning plan\nMost tutorials teach APL bottom-up; they go really deep into one topic. FastAI instead strives for top-down teaching. Therefore, we’ll try the approach of learning all of the glyphs first, as simply and quickly as we can. This has the added benefit that the documentation will become useable, since one glyph’s documentation often contains examples that use other glyphs.\nYou can find a table of all of the gylphs here:\n\n\n\nTables of APL glyphs: primitive functions, and primitive operators, via Dyalog docs.\n\n\nA good way to learn new concepts in APL (and in general) is to look at an example, try to predict what it’ll do before you run it, then run it and compare with your prediction. APL documentation is filled with examples which makes this approach even more powerful. The documentation will often include multiple examples as separate elements of an array.\nFor example, you should read the example for negate:\n\n- 3.2 ¯7 0\n\n¯3.2 7 0\n\n\n\nas three examples:\n\n- 3.2\n\n¯3.2\n\n\n\n\n- ¯7\n\n7\n\n\n\n\n- 0\n\n0\n\n\n\nWe then went on to learn about the following. My notes are sparse at this point - I highly recommend you check out the video instead!\n\nMinus sign; its monadic (negate) and dyadic (minus; subtract) forms.\n\nWe also use operator names when reading APL expressions. For example, ¯2 reads “negate 2”.\n\nArrays - we needed to know about arrays to understand minus’ examples.\n\nIn APL you create an array (like a vector in math and a tensor in deep learning) by adding spaces between elements.\n\nFunctions; monadic versus dyadic functions.\n\nEach glyph has two forms: monadic and dyadic. This isn’t the same as “monads” in Haskell - it simply means a function that takes one argument. In APL you don’t write functions like f(x,y,z). You either write them as f x if there’s one argument (monadic), or x f y if there are two (dyadic).\n\nPlus sign; its monadic (conjugate) and dyadic (plus) forms.\nComplex numbers - we needed to know about complex numbers to understand conjugate."
  },
  {
    "objectID": "posts/fastai-array-programming-day-1.html#qa",
    "href": "posts/fastai-array-programming-day-1.html#qa",
    "title": "fast.ai APL study group: Day 1",
    "section": "Q&A",
    "text": "Q&A\n\nAre parentheses used for clarifying expressions in APL?\nNot really. Since the precedence rules in APL are so simple, people don’t tend to use parentheses for clarity, but rather only if they’re absolutely needed."
  },
  {
    "objectID": "posts/editor.html",
    "href": "posts/editor.html",
    "title": "Build a text editor with Python and curses",
    "section": "",
    "text": "This article was featured in Episode 221 of the PythonBytes podcast by Michael Kennedy and Brian Okken.\nWe’re going to build a command line text editor from scratch in Python. If you’d like to learn the most out of this, I’d recommend to code along. When we encounter problems, I’ll try to state them first before suggesting a solution. I encourage you to pause and give yourself about fifteen minutes to try to solve it first. If you’re still stuck, move along and compare the solution with your own approach. It’s also totally fine if you simply read through at your leisure.\nOne more thing, if you struggle to even get started, reach out to me on twitter or via email and I’ll try my best to help.\nLet’s dive right in!"
  },
  {
    "objectID": "posts/editor.html#create-a-curses-application",
    "href": "posts/editor.html#create-a-curses-application",
    "title": "Build a text editor with Python and curses",
    "section": "Create a curses application",
    "text": "Create a curses application\nWe’ll use the curses library to avoid having to deal with low level issues like efficiently painting to the terminal screen and receiving user input. I’m going to skim over specifics about curses so we can focus on the editor itself. Please refer to the docs if you’d like to dig a little deeper.\nStart with a barebones curses application. Create a file, editor.py, and begin with the following:\nimport curses\n\n\ndef main(stdscr):\n    while True:\n        k = stdscr.getkey()\n\n\nif __name__ == \"__main__\":\n    curses.wrapper(main)\ncurses.wrapper prepares your terminal and later restores its original state. It then passes an object that represents the terminal screen, called stdscr (short for standard screen like standard in, out, and error)."
  },
  {
    "objectID": "posts/editor.html#a-way-out",
    "href": "posts/editor.html#a-way-out",
    "title": "Build a text editor with Python and curses",
    "section": "A way out",
    "text": "A way out\nProblem 1. If you run this, the only way out will be a keyboard interrupt with Ctrl-c. That’s not great, add a cleaner way out.\nSolution. stdscr.getkey blocks until a key is pressed, then stores it into the k variable, which is mapped to a sys.exit call to cleanly exit the application.\n(Comments like # ... signal that lines from the previous snippet are unchanged. In this case, import curses remains the first line of editor.py, and the if __name__ == \"__main__\": block remains at the end of the file.)\n# ...\nimport sys\n\n\ndef main(stdscr):\n    while True:\n        k = stdscr.getkey()\n        if k == \"q\":\n            sys.exit(0)\n\n# ...\nRunning the script should land you in a blank page. Then pressing q should get you back out.\n$ python editor.py"
  },
  {
    "objectID": "posts/editor.html#load-and-view-a-file",
    "href": "posts/editor.html#load-and-view-a-file",
    "title": "Build a text editor with Python and curses",
    "section": "Load and view a file",
    "text": "Load and view a file\nProblem 2. Before we can edit text, we’ll need to be able to display it. Add a way for a user to specify a file. Load that file into memory and display it in the curses window.\nSolution. Add an ArgumentParser that expects a single filename, reads the file’s contents to a variable. In the main loop, display each row of the file with stdscr.addstr.\nimport argparse\n\n# ...\n\ndef main(stdscr):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"filename\")\n    args = parser.parse_args()\n\n    with open(args.filename) as f:\n        buffer = f.readlines()\n\n    while True:\n        stdscr.erase()\n        for row, line in enumerate(buffer):\n            stdscr.addstr(row, 0, line)\n\n        k = stdscr.getkey()\n        if k == \"q\":\n            sys.exit(0)\n\n# ...\nThe contents of the file are stored in-memory until they’re ready to be rewritten into a file, hence the name buffer. Text editor buffers have some interesting implementations, but we won’t get into that just yet.\nRerun the application, this time pointing it to a file:\n$ python editor.py editor.py\nThe double editor.py isn’t a typo. We’re editing the source of the editor! Which you should now be able to view in your terminal."
  },
  {
    "objectID": "posts/editor.html#view-the-buffer-through-a-window",
    "href": "posts/editor.html#view-the-buffer-through-a-window",
    "title": "Build a text editor with Python and curses",
    "section": "View the buffer through a window",
    "text": "View the buffer through a window\nProblem 3. Depending on the size of your screen, you may have seen the following error:\n_curses.error: addwstr() returned ERR\nThe application is trying to draw the buffer beyond the length of the screen! In order to fix that, introduce a window with some width and height, and trim the rendered buffer to the width and height of the window.\nSolution. Add a Window class with n_rows and n_cols attributes. In the main function, instantiate a Window with size (curses.LINES - 1, curses.COLS - 1); these are constants that hold the number of lines and columns in the current curses window. Then trim the buffer before rendering it in the main loop.\n(The comment # ... def main(stdscr): hints that the text immediately following it belongs to the main function.)\n# ...\n\nclass Window:\n    def __init__(self, n_rows, n_cols):\n        self.n_rows = n_rows\n        self.n_cols = n_cols\n\n# ... def main(stdscr):\n\n    window = Window(curses.LINES - 1, curses.COLS - 1)\n\n    while True:\n        stdscr.erase()\n        for row, line in enumerate(buffer[:window.n_rows]):\n            stdscr.addstr(row, 0, line[:window.n_cols])\n\n# ..."
  },
  {
    "objectID": "posts/editor.html#move-the-cursor-through-the-buffer",
    "href": "posts/editor.html#move-the-cursor-through-the-buffer",
    "title": "Build a text editor with Python and curses",
    "section": "Move the cursor through the buffer",
    "text": "Move the cursor through the buffer\nProblem 4. The next step towards editing is cursor movement. Introduce a cursor, positioned at a given row and column. For now, initiate the cursor at (0, 0), then render the stdscr cursor at the current position. Don’t add any movement functionality just yet.\nSolution. Create a Cursor class with attributes row and col, both default to 0. Instantiate a Cursor in main, and call stdscr.move to the current cursor position in the main loop:\n# ...\n\nclass Cursor:\n    def __init__(self, row=0, col=0):\n        self.row = row\n        self.col = col\n\n# ... def main(stdscr):\n\n    window = Window(curses.LINES - 1, curses.COLS - 1)\n    cursor = Cursor()\n\n    while True:\n        stdscr.erase()\n        for row, line in enumerate(buffer[:window.n_rows]):\n            stdscr.addstr(row, 0, line[:window.n_cols])\n        stdscr.move(cursor.row, cursor.col)\n\n# ...\nThe cursor should now be displayed at (0, 0).\nProblem 5. Next, add cursor movement. Define a method for each direction: up, down, left, and right, each of which update the row or col as required. Then map the arrow keys to these cursor movement methods in the main loop.\nSolution.\n# ... class Cursor:\n\n    def up(self):\n        self.row -= 1\n\n    def down(self):\n        self.row += 1\n\n    def left(self):\n        self.col -= 1\n\n    def right(self):\n        self.col += 1\n\n# ... def main(stdscr):\n\n        k = stdscr.getkey()\n        if k == \"q\":\n            sys.exit(0)\n        elif k == \"KEY_UP\":\n            cursor.up()\n        elif k == \"KEY_DOWN\":\n            cursor.down()\n        elif k == \"KEY_LEFT\":\n            cursor.left()\n        elif k == \"KEY_RIGHT\":\n            cursor.right()\n\n# ...\nRerun the application and give it a spin. It works great! Until…\nProblem 6. It crashes when you try to move outside of the screen. We should probably restrict the cursor within the buffer.\n(You may have already solved this in your solution to Problem 5. If so, well done, and feel free to skip ahead!)\nSolution. Update the movement methods to only move if they’ll remain within the buffer. Since cursor movement now depends on buffer properties, we also need to pass the buffer through as an argument:\n# ... class Cursor:\n\n    def up(self):\n        if self.row > 0:\n            self.row -= 1\n\n    def down(self, buffer):\n        if self.row < len(buffer) - 1:\n            self.row += 1\n\n    def left(self):\n        if self.col > 0:\n            self.col -= 1\n\n    def right(self, buffer):\n        if self.col < len(buffer[self.row]):\n            self.col += 1\n\n# ... def main(stdscr):\n\n        k = stdscr.getkey()\n        if k == \"q\":\n            sys.exit(0)\n        elif k == \"KEY_UP\":\n            cursor.up()\n        elif k == \"KEY_DOWN\":\n            cursor.down(buffer)\n        elif k == \"KEY_LEFT\":\n            cursor.left()\n        elif k == \"KEY_RIGHT\":\n            cursor.right(buffer)\n\n# ...\nProblem 7. Almost there. Cursor movement should now mostly work, except that when moving to a shorter line the cursor will float outside the buffer. Fix that.\nSolution. Restrict the cursor’s col to be within the line we move to:\n# ... class Cursor:\n\n    def up(self, buffer):\n        if self.row > 0:\n            self.row -= 1\n            self._clamp_col(buffer)\n\n    def down(self, buffer):\n        if self.row < len(buffer) - 1:\n            self.row += 1\n            self._clamp_col(buffer)\n\n    def _clamp_col(self, buffer):\n        self.col = min(self.col, len(buffer[self.row]))\n\n# ... def main(stdscr):\n\n        k = stdscr.getkey()\n        if k == \"q\":\n            sys.exit(0)\n        elif k == \"KEY_UP\":\n            cursor.up(buffer)\n        # ...\n\n# ...\nProblem 8. This works alright, but it’s not the most convenient. Often when you move to a shorter line and back to the original line, you mean for the cursor to be as it was before you moved at all. Implement this functionality.\nSolution. We can achieve this by introducing a new variable, _col_hint, that keeps track of the last col explicitly moved to, and instead use that to reset the column after line movements.\nWhenever col is set by a horizontal movement, it should also update _col_hint to the same value. That value should be used when clamping. We can use a property and property setter to implement that.\n# ...\n\nclass Cursor:\n    def __init__(self, row=0, col=0, col_hint=None):\n        self.row = row\n        self._col = col\n        self._col_hint = col if col_hint is None else col_hint\n\n    @property\n    def col(self):\n        return self._col\n\n    @col.setter\n    def col(self, col):\n        self._col = col\n        self._col_hint = col\n\n    # ...\n\n    def _clamp_col(self, buffer):\n        self._col = min(self._col_hint, len(buffer[self.row]))\n\n# ...\nNote that _clamp_col sets the internal variable _col directly, avoiding the setter thus not resetting _col_hint.\nProblem 9. There’s one final addition that should also improve the user experience. If the cursor is moved horizontally outside the buffer, wrap to the start (or end) of the next (or previous) line.\nSolution.\n# ... class Cursor:\n\n    def left(self, buffer):\n        if self.col > 0:\n            self.col -= 1\n        elif self.row > 0:\n            self.row -= 1\n            self.col = len(buffer[self.row])\n\n    def right(self, buffer):\n        if self.col < len(buffer[self.row]):\n            self.col += 1\n        elif self.row < len(buffer) - 1:\n            self.row += 1\n            self.col = 0\n\n# ... def main(stdscr):\n\n        elif k == \"KEY_LEFT\":\n            cursor.left(buffer)\n\n# ...\nGive it a spin. All should work well except when the cursor moves outside of the window."
  },
  {
    "objectID": "posts/editor.html#scroll-the-window-to-the-cursor",
    "href": "posts/editor.html#scroll-the-window-to-the-cursor",
    "title": "Build a text editor with Python and curses",
    "section": "Scroll the window to the cursor",
    "text": "Scroll the window to the cursor\nProblem 10. We currently have no way of seeing any part of the buffer that’s outside the window. Worse still, we can also move the cursor outside of the window! Scroll the window vertically as the cursor moves. Don’t worry about horizontal scrolling for now.\nSolution. Add row and col attributes to the Window that track the current position of the window as it scrolls through the buffer (specifically, the position of the top-left of the window). Then add methods to scroll the window vertically.\nHaving learned from cursor movement, we’ll be sure to do the necessary checks the first time round: only scroll up if we’re not already at the top of the buffer and if the cursor exceeds the top of the window, and similarly for downward scrolling. In the main loop, scroll the window after moving the cursor. And finally, update where we start slicing the buffer when rendering.\n# ...\n\nclass Window:\n\n    def __init__(self, n_rows, n_cols, row=0, col=0):\n        self.n_rows = n_rows\n        self.n_cols = n_cols\n        self.row = row\n        self.col = col\n\n    @property\n    def bottom(self):\n        return self.row + self.n_rows - 1\n\n    def up(self, cursor):\n        if cursor.row == self.row - 1 and self.row > 0:\n            self.row -= 1\n\n    def down(self, buffer, cursor):\n        if cursor.row == self.bottom + 1 and self.bottom < len(buffer) - 1:\n            self.row += 1\n\n# ... def main(stdscr):\n\n    while True:\n        stdscr.erase()\n        for row, line in enumerate(buffer[window.row:window.row + window.n_rows]):\n            stdscr.addstr(row, 0, line)\n        stdscr.move(cursor.row, cursor.col)\n\n# ...\n        elif k == \"KEY_UP\":\n            cursor.up()\n            window.up(cursor)\n        elif k == \"KEY_DOWN\":\n            cursor.down(buffer)\n            window.down(buffer, cursor)\n        elif k == \"KEY_LEFT\":\n            cursor.left()\n            window.up(cursor)\n        elif k == \"KEY_RIGHT\":\n            cursor.right(buffer)\n            window.down(buffer, cursor)\n# ...\nNote that left and right movement may require vertical scrolling since the cursor may be wrapped to the previous or next line.\nThe last crucial piece is to translate the cursor’s actual position, which is in terms of the buffer, to be in terms of what’s displayed: the window. Add a translate method to the window, and use it to render the cursor:\n# ... class Window:\n\n    def translate(self, cursor):\n        return cursor.row - self.row, cursor.col - self.col\n\n# ... def main(stdscr):\n\n    while True:\n        stdscr.erase()\n        for row, line in enumerate(buffer[window.row:window.row + window.n_rows]):\n            stdscr.addstr(row, 0, line)\n        stdscr.move(*window.translate(cursor))\n\n# ...\nProblem 11. We’ve addressed vertical scrolling, but long lines still present an issue. There are two ways we might address long lines. We could either scroll the entire window with the cursor, as we did for vertical scrolling. This is how most editors work. Or we could scroll only the selected line to follow the cursor, which as far as I know is only implemented by nano. Let’s implement the second approach.\nThe desired behaviour is that when the cursor exceeds some margin away from the right edge of the window, the window should be moved one page to the right, and similarly for the left side.\nSolution. Add a horizontal_scroll method to Window that implements this, and call it after any cursor movements in the main loop.\n# ... class Window:\n\n    def horizontal_scroll(self, cursor, left_margin=5, right_margin=2):\n        n_pages = cursor.col // (self.n_cols - right_margin)\n        self.col = max(n_pages * self.n_cols - right_margin - left_margin, 0)\n\n# ... def main(stdscr):\n\n        elif k == \"KEY_UP\":\n            cursor.up()\n            window.up(cursor)\n            window.horizontal_scroll(cursor)\n        elif k == \"KEY_DOWN\":\n            cursor.down(buffer)\n            window.down(buffer, cursor)\n            window.horizontal_scroll(cursor)\n        elif k == \"KEY_LEFT\":\n            cursor.left()\n            window.up(cursor)\n            window.horizontal_scroll(cursor)\n        elif k == \"KEY_RIGHT\":\n            cursor.right(buffer)\n            window.down(buffer, cursor)\n            window.horizontal_scroll(cursor)\n\n# ...\nNext, update how the buffer renders long lines by including characters that indicate that a given line has more content on the left («) or right (»).\n# ... def main(stdscr):\n\n    while True:\n        stdscr.erase()\n        for row, line in enumerate(buffer[window.row:window.row + window.n_rows]):\n            if row == cursor.row - window.row and window.col > 0:\n                line = \"«\" + line[window.col + 1:]\n            if len(line) > window.n_cols:\n                line = line[:window.n_cols - 1] + \"»\"\n            stdscr.addstr(row, 0, line)\n        stdscr.move(*window.translate(cursor))\n\n    # ..."
  },
  {
    "objectID": "posts/editor.html#edit-the-buffer",
    "href": "posts/editor.html#edit-the-buffer",
    "title": "Build a text editor with Python and curses",
    "section": "Edit the buffer",
    "text": "Edit the buffer\nAnd now to the key ingredient, actually editing text!\nStart by adding a Buffer class that wraps the list of lines. Implement __len__ and __getitem__ so that any dependents of buffer needn’t change. Set buffer to a Buffer instance instead of the current list of lines.\n# ...\n\nclass Buffer:\n    def __init__(self, lines):\n        self.lines = lines\n\n    def __len__(self):\n        return len(self.lines)\n\n    def __getitem__(self, index):\n        return self.lines[index]\n\n# ... def main(stdscr):\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"filename\")\n    args = parser.parse_args()\n\n    with open(args.filename) as f:\n        buffer = Buffer(f.read().splitlines())\n\n# ...\nNow’s a good time for a tiny refactor: extract len(buffer) - 1 to the Buffer.bottom property. You might argue that this isn’t worth being extracted. My reasoning is that the last column in a line is len(buffer[row]) whereas the last row in a buffer is len(buffer) - 1, and I can never get it right the first time!\nI think it’s good to be aware of the kinds of bugs you tend to introduce, rather than to always follow a dogmatic approach. It also has a nice symmetry with Window.bottom, though that’s less important. It might be worth considering doing similar for len(buffer[row]), but I find that easy to remember and already concise.\n# ... class Buffer:\n\n    @property\n    def bottom(self):\n        return len(self) - 1\n\n# ... class Cursor:\n\n    def down(self, buffer):\n        if self.row < buffer.bottom:\n            self.row += 1\n            self._clamp_col(buffer)\n\n    # ...\n\n    def right(self, buffer):\n        if self.col < len(buffer[self.row]):\n            self.col += 1\n        elif self.row < buffer.bottom:\n            self.row += 1\n            self.col = 0\n\n# ... class Window:\n\n    def down(self, buffer, cursor):\n        if cursor.row == self.bottom + 1 and self.bottom < buffer.bottom:\n            self.row += 1\n\n# ...\nWe’ll be adding three methods to the buffer: insert, split, and delete.\n\nInsert a string into the buffer\nProblem 12. If an unmapped key is pressed, insert it into the buffer at the current cursor position.\nSolution.\nSince the buffer stores text as a list of lines, and the cursor moves through a two-dimensional space, there’s a tiny bit of work we need to do to insert text at a given cursor.\nPop the line under the cursor, split it at the cursor, and concatenate the before part, the string to be inserted, and the after part. Insert the concatenated string into the buffer at the cursor. And as usual, call the method in the main loop. This case differs slightly from previous, in that we’ll map all unmapped keys to Buffer.insert. That’s probably not ideal, for example, a user might enter Ctrl-i which will write ^I to the buffer, but it’ll do for now.\n# ... class Buffer:\n\n    def insert(self, cursor, string):\n        row, col = cursor.row, cursor.col\n        current = self.lines.pop(row)\n        new = current[:col] + string + current[col:]\n        self.lines.insert(row, new)\n\n# ... def main(stdscr):\n\n    if k == \"q\":\n        sys.exit(0)\n    # ...\n    else:\n        buffer.insert(cursor, k)\n\n# ...\nTest it out. It’ll insert text, but won’t move the cursor after the inserted text. All we need to do is move right for each inserted character. Since we already have a command to move the cursor right (and scroll the window as needed), now’s the time to extract a right function and re-use it:\n# ...\n\ndef right(window, buffer, cursor):\n    cursor.right(buffer)\n    window.down(buffer, cursor)\n    window.horizontal_scroll(cursor)\n\n# ... def main(stdscr):\n\n    elif k == \"KEY_RIGHT\":\n        right(window, buffer, cursor)\n    # ...\n    else:\n        buffer.insert(cursor, k)\n        for _ in k:\n            right(window, buffer, cursor)\n\n# ...\n\n\nSplit a line in the buffer\nProbem 12. If you hit enter, you won’t get the expected result, which is to split the line at the cursor.\nSolution. Implement split as below, similar to insert.\n# ... class Buffer:\n\n    def split(self, cursor):\n        row, col = cursor.row, cursor.col\n        current = self.lines.pop(row)\n        self.lines.insert(row, current[:col])\n        self.lines.insert(row + 1, current[col:])\n\n# ... def main(stdscr):\n\n    elif k == \"\\n\":\n        buffer.split(cursor)\n        right(window, buffer, cursor)\n\n# ...\n\n\nDelete a character from the buffer\nProblem 13. As in the previous section, hitting delete or backspace won’t give the expected result. Start by implementing a delete command, bound to the delete key, that deletes the character under the cursor.\nSolution. Add a delete method. If the cursor is at the last position in the buffer, don’t do anything. Otherwise, there are two options. Either the cursor is inside a line, then follow similar logic to insert but instead of adding a string remove a character. Or the cursor is at the end of the line, then join the current line to the next.\n# ... class Buffer:\n\n    def delete(self, cursor):\n        row, col = cursor.row, cursor.col\n        if (row, col) < (self.bottom, len(self[row])):\n            current = self.lines.pop(row)\n            if col < len(self[row]):\n                new = current[:col] + current[col + 1:]\n                self.lines.insert(row, new)\n            else:\n                next = self.lines.pop(row)\n                new = current + next\n                self.lines.insert(row, new)\n\n# ... def main(stdscr):\n\n    elif k in (\"KEY_DELETE\", \"\\x04\"):\n        buffer.delete(cursor)\n\n# ...\nOn MacOS, curses doesn’t correctly decode the backspace and delete keys, they’re instead returned as \\x7f and \\x04 respectively. I haven’t found a satisfactory answer for why this is the case. If you know, I’d love to hear!\nProblem 14. Implement backspace.\nSolution. Backspace can be implemented by moving left and then deleting. Just as we extracted a right function for insertion, we’ll extract a left function here:\n# ...\n\ndef left(window, buffer, cursor):\n    cursor.left(buffer)\n    window.up(cursor)\n    window.horizontal_scroll(cursor)\n\n# ... def main(stdscr):\n\n    elif k in (\"KEY_BACKSPACE\", \"\\x7f\"):\n        if (cursor.row, cursor.col) > (0, 0):\n            left(window, buffer, cursor)\n            buffer.delete(cursor)\n\n# ...\nAnd look at that! You’ve built a minimal yet functional text editor.\nProblem 15. There’s one key piece of functionality still missing: saving the edited file. I’ll leave that as the final unsolved problem."
  },
  {
    "objectID": "posts/editor.html#what-next",
    "href": "posts/editor.html#what-next",
    "title": "Build a text editor with Python and curses",
    "section": "What next?",
    "text": "What next?\nI hope you enjoyed working through this, and that you learned something new. If you did or if you have any other questions or comments, feel free to reach out to me on twitter or via email.\nIf this whet your appetite and you’re looking for more, here are some exercises you might find interesting, in roughly increasing difficulty:\n\nRemap cursor movement to Ctrl-p (up), Ctrl-n (down), Ctrl-b (left), and Ctrl-f (right).\nAdd page up and page down commands.\nAdd a command to save the buffer to a file.\nRewrite horizontal scrolling to move the entire window rather than only the current line.\nAdd a status line to the bottom of the window that displays the name of the file being edited and the current cursor position.\nAdd commands to move one word left or right.\nIf the buffer is modified and not yet saved, print a message in the status line and don’t let the user exit. Add a force exit command as well.\nRewrite the application so that there’s no mutable state. I’ve found dataclasses with the dataclass.replace function a convenient way to write applications around immutable objects."
  },
  {
    "objectID": "posts/editor.html#credits",
    "href": "posts/editor.html#credits",
    "title": "Build a text editor with Python and curses",
    "section": "Credits",
    "text": "Credits\nMany thanks to the following people and projects for sharing their great work, upon which a lot of this was based!\n\nMany thanks to Pavel Spirhanzl and Alexandre Pajak for their keen eyes in identifying bugs in early versions.\nGary Bernhardt’s Text Editor From Scratch screencast.\nAnthony Sottile’s babi.\nnano source.\nEmacs source. In my opinion, the best way to explore the source is through Emacs’ built-in help commands."
  },
  {
    "objectID": "posts/tools-wishlist.html",
    "href": "posts/tools-wishlist.html",
    "title": "Tools wishlist",
    "section": "",
    "text": "I care a lot about the tools I use. You can see this by looking at how much time I’ve spent on my dotfiles.1 It’s not about being more “productive”. It’s about how it feels to use them. I just can’t help myself but tinker until it feels right.\nI also try my best to understand more generally what it is I’m getting from each tool in my toolbox. That gives me good grounds to cut through the hype when new tools come along. To that end, here is a list of requirements I currently hold for the tools I use (kind of) in decreasing order of importance:\n\nData ownership and privacy. I must own my data. No one else must be able to touch my data without my express permission. Promises, unfortunately, aren’t good enough. I find it incredibly sad that this item rules out many otherwise amazing tools out there.\nSpeed. There should be minimal lag between action and outcome. The application should never hang unless for a very obviously long-running process. Even then, input and output shouldn’t freeze.\nFuzzy finding. Choosing from a set of commands should always be through an interface that allows me to incrementally narrow the set via fuzzy search. Fuzzy, at the very least, meaning that letters can be left out.\nIdeally, there’d be fuzzy finding all the way down to auto-completing single keywords. Though, weirdly enough, I’ve still not found an auto-completion system that satisfies my speed requirement. They all seem to introduce a sub-second input lag that grinds my gears. PyCharm does a great job, but doesn’t satisfy my other requirements.\nThis is sort of a special case of a more general principle that if there’s a repeated action that the computer could guess with very high accuracy, it should do the work for me. For actions that I perform exceedingly often, I’d bind them to a simple keyboard shortcut. I like VIM’s modal editing because it gives me far more keys to bind.\nNo visual clutter. There must be an option to disable menu bars, tool bars, icons. Because I prefer keyboard-driven and I have fuzzy finding, I often don’t really need menus/toolbars. In cases where information lends itself well to a visual representation, I prefer it to appear as needed, or if persistent, for it to be compact. For example, a bar displaying open tabs could be a single line of text.\nKeyboard-driven. I’m not against the mouse at all. I very happily use it all the time. But between emails, Slack messages, documentation, issue descriptions, code reviews, and good ol’ programming, my work involves tons of writing. And when I’m writing, if there’s even a single action that requires changing my hand position every few minutes, it becomes frustrating really quickly.\nSome of the applications I use aren’t fully keyboard-driven. I don’t really mind that when the primary mode of use isn’t typing. For example, creating presentations, managing tasks (I use Things), calendars, Slack and Twitter where I’m reading at least as much as I’m writing, and browsing the web.\nIdeally, I should also be able to reconfigure keyboard shortcuts arbitrarily, and for any action. Unfortunately many modern applications fall short here, but there are typically workarounds.\nThis is a special case of keeping similar actions that occur in similar contexts “close”. If the context is that I’m already typing a bunch, actions should be a keyboard shortcut or fuzzy find away. If the context requires pointing and clicking, then mouse shortcuts, toolbars, and maybe even pie menus are better. For this reason, I’m also not really a fan of keyboard-driven tiling window managers.\nThemes. I’m red-green colour-blind, and not all default colour schemes account for this. I’m also a picky about my colour schemes, fonts, and overall theme. I also like switching them up every now and then. Most tools allow this these days.\n\n\n\n\n\nFootnotes\n\n\nCaution: They’re not always up-to-date, or easy to understand, and I’ve made no effort to ensure they work for anyone else.↩︎"
  },
  {
    "objectID": "posts/notebook-best-practices.html",
    "href": "posts/notebook-best-practices.html",
    "title": "Notebook best practices",
    "section": "",
    "text": "Notebooks are an incredibly powerful and flexible medium… which can be overwhelming. We just published an article in the nbdev docs sharing everything we know about writing great notebooks after years of working with nbdev.\nHere are 3 tips to get you started. Check out the full article for more!\n\n\n\nMarie Curie’s research notebook dated 19-21 January 1900 (source).\n\n\n\n1. Use Jupyter’s rich display features to supercharge your users\nJupyter lets your objects render themselves with rich formatting. Many libraries have taken advantage of this to include rich displays of their objects, which helps with prototyping, debugging, presenting your work, and makes the entire experience more delightful.\nWe highly recommend using these in your own notebooks, and creating rich displays of objects in your own libraries. Here are a few examples to get you started:\n\nRDKit moleculefastai’s learning rate finderMermaid + Graphviz diagram via QuartoColor – a minimal hackable example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can add rich representations to your own objects by defining a _repr_markdown_ method that returns markdown text (which may also include HTML/CSS). See the full Color example in the article to get started.\n\n\n2. Use lots of code examples\n…and convert some of them to tests using assertions. nbdev blurs the lines between code, docs, and tests. Every code cell is run as a test (unless it’s explicitly marked otherwise), and any error in the cell fails the test.\nfast.ai’s vision augmentation notebook is a great example that also uses rich display features:\n\n\n\n\n\n\n\n3. Know which form of notebook you’re writing\nDecide which form of notebook you’re writing. We’re fans of the Diátaxis system which classifies documentation into four forms: tutorials, how-to guides, explanations, and references. They’ve laid this out beautifully in the following diagram:\n\n\n\n\n\n\n\nFurther reading\nThese are only 3 of many more best practices detailed in the full article. We also include a full example that converts a numpy docstring to a notebook-friendly format following these practices.\nYou can follow the conversation on Twitter:\n\n\nNotebooks are an incredibly powerful and flexible medium… which can be overwhelmingHere's everything we know about writing great notebooks after years of working with #nbdevhttps://t.co/yihcwasDvd\n\n— Wasim Lorgat (@wasimlorgat) September 19, 2022\n\n\n\n\nAppendix: Marie Curie’s research notebook\nI really love the preview image! It’s an excerpt from Marie Curie’s research notebook dated 19-21 January 1900. I could pick out a few words here and there: a l’air (looks), rien (nothing), alumin (aluminium), frod (cold), chauffé (heated), and parafin. Unfortunately, I don’t know much more than that. Please let me know if you do!"
  },
  {
    "objectID": "posts/derivations.html",
    "href": "posts/derivations.html",
    "title": "Include derivations",
    "section": "",
    "text": "Include derivations! It’s perfectly fine to use clever techniques and definitions, such as rleDecode = (uncurry replicate =<<) for decoding run-length encoded lists of tuples, but in the comments, include the original giant definition which you progressively refined into a short diamond! Even better, add a test (like a QuickCheck property) where you demonstrate that the output from the two are the same. If you are optimizing, somewhere hold onto the slow ones which you know are correct. Derivations are brilliant documentation of your intent, they provide numerous alternate implementations which might work if the current one breaks, and they give the future Haskellers a view of how you were thinking.\n— Gwern, Resilient Haskell Software\nInclude derivations! An idea I hadn’t seen before. In fact, an idea counter to what I’ve seen. It got me thinking about comments and documentation."
  },
  {
    "objectID": "posts/derivations.html#prefer-self-documenting-code-over-comments",
    "href": "posts/derivations.html#prefer-self-documenting-code-over-comments",
    "title": "Include derivations",
    "section": "Prefer self-documenting code over comments",
    "text": "Prefer self-documenting code over comments\nI’m sure you’ve heard this advice before. I’ve heard it and even given it many times.\nThe argument goes something like this: comments tend to become out of sync with the code they’re commenting. While your code is tested by its users and by your test suite, there’s nothing to ensure that comments remain correct.1 It seems natural then that without any sticking force your comments become outdated.\nYet I still find myself smiling when I come across well-commented code. Why the discrepency?"
  },
  {
    "objectID": "posts/derivations.html#developer--vs-user-oriented-comments",
    "href": "posts/derivations.html#developer--vs-user-oriented-comments",
    "title": "Include derivations",
    "section": "Developer- vs user-oriented comments",
    "text": "Developer- vs user-oriented comments\nAny given program has at least two groups of people interacting with it: developers, who directly change and extend the underlying functionality; and users, who use that functionality.\nDevelopers and users benefit from different forms of documentation. Users typically don’t need to know the full extent of implementation details and the context in which decisions were made, instead they need to know the interface of the various components, how those components interact, and how to compose them to achieve a desired goal. Developers, on the other hand, need to know the implementation details in all their glory.\nFor example, while users probably don’t need to know why a specific method was chosen to decode run-length encoded lists of tuples, this is absolutely the type of information a developer needs to make good decisions about how to further extend that functionality. In the same way users probably don’t need to know why the specific method was chosen, developers probably don’t need the function’s arguments redescribed to them each time. Self-documenting functions and argument names do just fine. I increasingly see inline comments and docstrings for the purpose of auto-generating user docs as redundant noise while working with the code. Perhaps a topic for a future post. Naturally, comments describing those arguments gradually fade away from our attention, and are left outdated.\nI view developer-oriented comments as distinctly different from user-oriented comments. Someone from the past is talking directly to me: warning me of a trap, describing a hard-to-find workaround, or lamenting why this “temporary hack” should be temporary. These feel like an extension of the code, thus I consider them less susceptible to becoming outdated."
  },
  {
    "objectID": "posts/derivations.html#takeaway-everythings-hard-and-there-are-no-easy-answers",
    "href": "posts/derivations.html#takeaway-everythings-hard-and-there-are-no-easy-answers",
    "title": "Include derivations",
    "section": "Takeaway: everything’s hard and there are no easy answers",
    "text": "Takeaway: everything’s hard and there are no easy answers\nThere are (almost) no absolutes. There are guidelines, and they serve you well as you’re learning the ropes. But as your expertise grows, you learn to see them as the fuzzy boundaries that they are.\nIt makes sense though. As beginners, we aren’t primed for the nuance required to understand the reality in all of its complexity. But always remember that guidelines are only approximations and that reality is more complex."
  },
  {
    "objectID": "posts/jupyter-server-a-whirlwind-tour.html",
    "href": "posts/jupyter-server-a-whirlwind-tour.html",
    "title": "Jupyter Server: A whirlwind tour",
    "section": "",
    "text": "Photo by Planet Volumes on Unsplash\nThis blog post (and the source notebook) is an executable playground for understanding how to communicate with Jupyter Servers. You can think of it as a barebones Jupyter frontend, since we’ll be implementing the full lifecycle including creating a new notebook, writing and executing code cells, and shutting down the server.\nI’m building my own native macOS Jupyter frontend and writing about my experience and learnings along the way. In order to do that, I need to be familiar with how Jupyter Servers works.\nMy approach to learning this was a combination of using Chrome dev tools to inspect network requests in Jupyter Lab, and reading the wonderful Jupyter Server docs (particularly the REST API reference). I’ll include links to the relevant docs in each section below.\nLet’s get started!"
  },
  {
    "objectID": "posts/jupyter-server-a-whirlwind-tour.html#starting-the-server",
    "href": "posts/jupyter-server-a-whirlwind-tour.html#starting-the-server",
    "title": "Jupyter Server: A whirlwind tour",
    "section": "Starting the server",
    "text": "Starting the server\nTo start, ensure that you’re running a Jupyter Server in another process (e.g. in a terminal) by entering the following command:\njupyter server\nOnce the server is running, update the url_with_token variable below to match what’s displayed in the terminal output. For example, it should output something like this:\n[C 2023-01-07 12:03:57.482 ServerApp]\n\n    To access the server, open this file in a browser:\n        file:///Users/seem/Library/Jupyter/runtime/jpserver-80287-open.html\n    Or copy and paste one of these URLs:\n        http://localhost:8889/?token=72b22f0cee26baaa6aed492b6fed5a010d57bd6c0e1adcce\n     or http://127.0.0.1:8889/?token=72b22f0cee26baaa6aed492b6fed5a010d57bd6c0e1adcce\n\n# NB: Update this based on your terminal output\nurl_with_token = 'http://localhost:8889/?token=e78ceb3114cb10d50f64485b18e3052c66861616166e0bab'"
  },
  {
    "objectID": "posts/jupyter-server-a-whirlwind-tour.html#authenticating",
    "href": "posts/jupyter-server-a-whirlwind-tour.html#authenticating",
    "title": "Jupyter Server: A whirlwind tour",
    "section": "Authenticating",
    "text": "Authenticating\nFirst, we’ll do a quick check that there is a server at the defined url. We need to get the URL without the token query parameter:\n\nfrom urllib.parse import urlparse\n\n\nurl = urlparse(url_with_token)._replace(query=None).geturl()\nurl\n\n'http://localhost:8889/'\n\n\nNow we can make the request:\n\nimport requests\n\n\nrequests.get(url)\n\n<Response [200]>\n\n\nA 200 response means that the server processed the request successfully.\nNext we need to authenticate. What happens if we try to make a request to an endpoint that requires authentication, for example GET /api/contents?\n\nrequests.get(url + 'api/contents')\n\n<Response [403]>\n\n\nIt fails with 403 Forbidden.\nIf we include our token in the Authorization header:\n\ntoken = urlparse(url_with_token).query.split('=')[-1]\nheaders = {'Authorization': f'token {token}'}\nrequests.get(url + 'api/contents', headers=headers)\n\n<Response [200]>\n\n\n… it works!\nLet’s create a requests.Session so we don’t have to keep specifying the header:\n\nsession = requests.Session()\nsession.headers.update(headers)"
  },
  {
    "objectID": "posts/jupyter-server-a-whirlwind-tour.html#managing-files",
    "href": "posts/jupyter-server-a-whirlwind-tour.html#managing-files",
    "title": "Jupyter Server: A whirlwind tour",
    "section": "Managing files",
    "text": "Managing files\nJupyter Server lets you manage files via the Contents API. Browser frontends access this via the /api/contents REST API.\nLet’s use the Contents API to create a file, rename it, and write some contents to it.\n\nList the contents of a directory\nGET /api/contents/<path> returns the contents of the file or directory at path. You can think of it as ls for Jupyter Server:\n\nsession.get(url + 'api/contents').json()\n\n{'name': '',\n 'path': '',\n 'last_modified': '2023-01-19T05:58:38.693411Z',\n 'created': '2023-01-19T05:58:38.693411Z',\n 'content': [],\n 'format': 'json',\n 'mimetype': None,\n 'size': None,\n 'writable': True,\n 'type': 'directory'}\n\n\nSince the directory is currently empty, content is an empty list.\n\n\nCreate an empty notebook\nPOST /api/contents/<path> creates an empty file in the directory at path. You can specify the type of the file in the request body:\n\nsession.post(url + 'api/contents', json={'type': 'notebook'})\n\n<Response [201]>\n\n\nThe 201 status code means that the request succeeded and a resource was created.\nLet’s confirm that the file exists with GET /api/contents:\n\nsession.get(url + 'api/contents').json()\n\n{'name': '',\n 'path': '',\n 'last_modified': '2023-01-19T06:01:01.089699Z',\n 'created': '2023-01-19T06:01:01.089699Z',\n 'content': [{'name': 'Untitled.ipynb',\n   'path': 'Untitled.ipynb',\n   'last_modified': '2023-01-19T06:01:01.090600Z',\n   'created': '2023-01-19T06:01:01.090600Z',\n   'content': None,\n   'format': None,\n   'mimetype': None,\n   'size': 72,\n   'writable': True,\n   'type': 'notebook'}],\n 'format': 'json',\n 'mimetype': None,\n 'size': None,\n 'writable': True,\n 'type': 'directory'}\n\n\nThe response is a nested dict. The root dict refers to the root directory as before, however, content now contains the newly created notebook named Untitled.ipynb.\nWe can get the contents of this file using the same method but referring to the file’s path i.e. GET /api/contents/<path>:\n\ndata = session.get(url + 'api/contents/Untitled.ipynb').json()\ndata\n\n{'name': 'Untitled.ipynb',\n 'path': 'Untitled.ipynb',\n 'last_modified': '2023-01-19T06:01:01.090600Z',\n 'created': '2023-01-19T06:01:01.090600Z',\n 'content': {'cells': [], 'metadata': {}, 'nbformat': 4, 'nbformat_minor': 5},\n 'format': 'json',\n 'mimetype': None,\n 'size': 72,\n 'writable': True,\n 'type': 'notebook'}\n\n\nWe’re probably most interested in content, which contains the JSON content of the notebook:\n\ndata['content']\n\n{'cells': [], 'metadata': {}, 'nbformat': 4, 'nbformat_minor': 5}\n\n\nFor now, the notebook only has some metadata, and cells is empty.\n\n\nRename a notebook\nOur newly created file is still named Untitled.ipynb. Let’s rename it to sum.ipynb with PATCH /api/contents/<path>:\n\nsession.patch(url + 'api/contents/Untitled.ipynb', json={'path': 'sum.ipynb'}).json()\n\n{'name': 'sum.ipynb',\n 'path': 'sum.ipynb',\n 'last_modified': '2023-01-19T06:01:01.090600Z',\n 'created': '2023-01-19T06:01:01.210202Z',\n 'content': None,\n 'format': None,\n 'mimetype': None,\n 'size': 72,\n 'writable': True,\n 'type': 'notebook'}\n\n\nConfirm that it’s been renamed. Untitled.ipynb no longer exists:\n\nsession.get(url + 'api/contents/Untitled.ipynb').json()\n\n{'message': 'No such file or directory: Untitled.ipynb', 'reason': None}\n\n\n… but sum.ipynb does:\n\nsession.get(url + 'api/contents/sum.ipynb').json()\n\n{'name': 'sum.ipynb',\n 'path': 'sum.ipynb',\n 'last_modified': '2023-01-19T06:01:01.090600Z',\n 'created': '2023-01-19T06:01:01.210202Z',\n 'content': {'cells': [], 'metadata': {}, 'nbformat': 4, 'nbformat_minor': 5},\n 'format': 'json',\n 'mimetype': None,\n 'size': 72,\n 'writable': True,\n 'type': 'notebook'}\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can also create a file with a specified name using PUT /api/contents/<path>, instead of letting the server find a unique named prefixed with Untitled.\n\n\n\n\nUpdate a notebook’s contents\nCreate a cell and append it to existing contents:\n\ncell = {\n    'cell_type': 'code',\n    'id': '0',\n    'metadata': {},\n    'source': [\n        '1 + 1\\n',\n    ],\n    'outputs': [],\n    'execution_count': 0,\n}\ndata = session.get(url + 'api/contents/sum.ipynb').json()\ndata['content']['cells'].append(cell)\n\nUpdate the notebook’s contents using PUT /api/contents/<path>:\n\nsession.put(url + 'api/contents/sum.ipynb', json={'content': data['content'], 'type': 'notebook'})\n\n<Response [200]>\n\n\nConfirm that the notebook’s been updated. Note that last_modified and content have both updated:\n\nsession.get(url + 'api/contents/sum.ipynb').json()\n\n{'name': 'sum.ipynb',\n 'path': 'sum.ipynb',\n 'last_modified': '2023-01-19T06:01:01.348274Z',\n 'created': '2023-01-19T06:01:01.348274Z',\n 'content': {'cells': [{'cell_type': 'code',\n    'execution_count': 0,\n    'id': '0',\n    'metadata': {'trusted': True},\n    'outputs': [],\n    'source': '1 + 1\\n'}],\n  'metadata': {},\n  'nbformat': 4,\n  'nbformat_minor': 5},\n 'format': 'json',\n 'mimetype': None,\n 'size': 216,\n 'writable': True,\n 'type': 'notebook'}"
  },
  {
    "objectID": "posts/jupyter-server-a-whirlwind-tour.html#executing-code",
    "href": "posts/jupyter-server-a-whirlwind-tour.html#executing-code",
    "title": "Jupyter Server: A whirlwind tour",
    "section": "Executing code",
    "text": "Executing code\nMost of the functionality available inside a Jupyter Notebook in your browser is achieved by communicating with the server via websockets. This includes executing code as well as code completion.\nLet’s execute a very simple bit of code on the server.\n\nStart a session\nList open sessions with GET /api/sessions:\n\nsession.get(url + 'api/sessions').json()\n\n[]\n\n\nFirst we need to choose a kernel specification. Here are the available options on my computer – yours will likely differ:\n\nsession.get(url + 'api/kernelspecs').json()\n\n{'default': 'python3',\n 'kernelspecs': {'dyalog-kernel': {'name': 'dyalog-kernel',\n   'spec': {'argv': ['python3',\n     '-m',\n     'dyalog_kernel',\n     '-f',\n     '{connection_file}'],\n    'env': {},\n    'display_name': 'Dyalog APL',\n    'language': 'apl',\n    'interrupt_mode': 'signal',\n    'metadata': {}},\n   'resources': {'kernel.js': '/kernelspecs/dyalog-kernel/kernel.js'}},\n  'python3': {'name': 'python3',\n   'spec': {'argv': ['python',\n     '-m',\n     'ipykernel_launcher',\n     '-f',\n     '{connection_file}'],\n    'env': {},\n    'display_name': 'Python 3 (ipykernel)',\n    'language': 'python',\n    'interrupt_mode': 'signal',\n    'metadata': {'debugger': True}},\n   'resources': {'logo-64x64': '/kernelspecs/python3/logo-64x64.png',\n    'logo-32x32': '/kernelspecs/python3/logo-32x32.png',\n    'logo-svg': '/kernelspecs/python3/logo-svg.svg'}}}}\n\n\nCreate a new session with POST /api/sessions with the python3 kernelspec:\n\ndata = session.post(url + 'api/sessions', json={'kernel': {'name': 'python3'}, 'name': 'sum.ipynb', 'path': 'sum.ipynb', 'type': 'notebook'}).json()\ndata\n\n{'id': '5730d780-fa1f-446e-b8ad-f3e66be9d063',\n 'path': 'sum.ipynb',\n 'name': 'sum.ipynb',\n 'type': 'notebook',\n 'kernel': {'id': '760db402-af7f-4559-aa39-5518d2107b14',\n  'name': 'python3',\n  'last_activity': '2023-01-19T06:01:01.734770Z',\n  'execution_state': 'starting',\n  'connections': 0},\n 'notebook': {'path': 'sum.ipynb', 'name': 'sum.ipynb'}}\n\n\nNow that a session exists, we can connect to a websocket. We’ll need the kernel_id and session_id to do that, so let’s store them for the next step:\n\nkernel_id = data['kernel']['id']\nsession_id = data['id']\n\n\n\nCommunicate over WebSockets\nFirst, let’s craft a message to request an execution – you can try changing the value of the code variable below to execute something else:\n\nimport uuid\n\ncode = '1 + 1'\ncode_msg_id = str(uuid.uuid1())\ncode_msg = {'channel': 'shell',\n            'content': {'silent': False, 'code': code},\n            'header': {'msg_id': code_msg_id, 'msg_type':'execute_request'},\n            'metadata': {},\n            'parent_header':{}}\n\nNow we can send the message to the server and receive all responses.\nWe’ll use the websocket-client library. You might also want to consider the websockets library which is asynchronous.\n\nimport json\nfrom contextlib import closing\nfrom websocket import create_connection, WebSocketTimeoutException\n\ndef recv_all(conn):\n    while True:\n        try: msg = json.loads(conn.recv())\n        except WebSocketTimeoutException: break\n        print(f\"  type: {msg['msg_type']:16} content: {msg['content']}\")\n\nws_base_url = urlparse(url)._replace(scheme='ws').geturl()\nws_url = ws_base_url + f'api/kernels/{kernel_id}/channels?session_id={session_id}'\n\nwith closing(create_connection(ws_url, header=headers, timeout=1)) as conn:\n    print('Receiving initial messages\\n')\n    recv_all(conn)\n    print('\\nSending execute_request\\n')\n    conn.send(json.dumps(code_msg))\n    print('Receiving execute_reply\\n')\n    recv_all(conn)\n\nReceiving initial messages\n\n  type: status           content: {'execution_state': 'busy'}\n  type: status           content: {'execution_state': 'idle'}\n  type: status           content: {'execution_state': 'idle'}\n\nSending execute_request\n\nReceiving execute_reply\n\n  type: status           content: {'execution_state': 'busy'}\n  type: execute_input    content: {'code': '1 + 1', 'execution_count': 1}\n  type: execute_result   content: {'data': {'text/plain': '2'}, 'metadata': {}, 'execution_count': 1}\n  type: status           content: {'execution_state': 'idle'}\n  type: execute_reply    content: {'status': 'ok', 'execution_count': 1, 'user_expressions': {}, 'payload': []}\n\n\nYay! We successfully executed code on the server via websockets.\nYou can learn more about Jupyter’s messaging specification in the Jupyter Client docs."
  },
  {
    "objectID": "posts/jupyter-server-a-whirlwind-tour.html#cleanup",
    "href": "posts/jupyter-server-a-whirlwind-tour.html#cleanup",
    "title": "Jupyter Server: A whirlwind tour",
    "section": "Cleanup",
    "text": "Cleanup\nIt’s always good practice to cleanup after ourselves, particularly if we share the server with other users.\nLet’s close our session and shutdown the server (although we probably wouldn’t shut it down if we shared it with others!).\n\nClose the session\nSince we’re done with the session, we can close it via DELETE /api/sessions/<session_id>:\n\nsession.delete(url + f'api/sessions/{session_id}')\n\n<Response [204]>\n\n\n\n\nShutdown the server\nFinally, shutdown the server via POST /api/shutdown.\n\nsession.post(url + 'api/shutdown')\n\n<Response [200]>\n\n\n… and confirm that it’s been shutdown correctly:\n\ntry: session.get(url)\nexcept requests.exceptions.ConnectionError: print('Server has been successfully shutdown!')\n\nServer has been successfully shutdown!\n\n\nAll done!"
  },
  {
    "objectID": "posts/jupyter-server-a-whirlwind-tour.html#next-steps",
    "href": "posts/jupyter-server-a-whirlwind-tour.html#next-steps",
    "title": "Jupyter Server: A whirlwind tour",
    "section": "Next steps",
    "text": "Next steps\nCongrats! If you followed all the way to the end, you’ve now created a barebones Jupyter frontend. Here are some directions you might consider to take this further:\n\nHow would you implement other notebook features like code completion?\nHow does Jupyter’s trust system work?\nHow would you implement Jupyter’s checkpointing system?\nCan you redo this in another language?\nHow would you design and build your own UI on top of this?\n\nAs for me, my next step is to start translating these into Swift as part of the native macOS Jupyter frontend I’m building.\nLet me know on Twitter or via email if you enjoyed this or if you have any questions!"
  },
  {
    "objectID": "posts/hats.html",
    "href": "posts/hats.html",
    "title": "Hats and productivity",
    "section": "",
    "text": "AI-generated image of hats (source and prompt).\n\n\nSometimes I feel like pursuing depth. Scribbling through a difficult problem. Other times it’s about breadth. Searching for existing solutions to my problem. Sometimes it’s about people. Connecting with others, seeing what they’re working on, what they’re thinking about, and how we might help each other. Sometimes it’s about planning, or otherwise separating coulds from shoulds.\nAll of these require a different hat, a different set of skills and tools, and there’s a cost to switching. But more subtle than that, there’s a cost to wearing the wrong hat at the wrong time. I understand that it’s unrealistic to expect absolute freedom here. In fact, I’m not sure that’s ideal. Too much freedom is itself a source of pressure. A vacuum. But somewhere in the middle, where there’s just enough pressure to push you forward, together with just enough room to wear the right hat, there’s a sweet spot.\nYou might be wondering how anything would get done if we decided what work to do on a whim. I think this is one of the defining factors of a great team. A team with diversity in strengths, weaknesses, backgrounds, and more generally, modes of thought, is like a polyphase system. It provides constant power transfer, despite its individual conductors peaking at different points in time, ultimately delivering more power than single-phase systems for the same voltage."
  },
  {
    "objectID": "posts/pdlog.html",
    "href": "posts/pdlog.html",
    "title": "Introducing pdlog",
    "section": "",
    "text": "Most data problems don’t need the horsepower of Spark or Hadoop. If all of your data fits comfortably in memory, pandas may be a great fit. pandas is my goto for quickly building out production pipelines that are both efficient and easy to maintain.\nOne issue I’ve run into is that pandas doesn’t natively log. Fortunately, it allows extending the dataframe API with accessors. We have since implemented an accessor for logging in the publicly avilable pdlog package.\nTo get started:\n\nInstall pdlog:\npip install pdlog\nImport pdlog in your application:\nimport pdlog\nAdd .log before your method calls:\ndf = df.log.dropna()\nThey’ll now log useful information about the operation, for example:\n2020-05-26 20:55:30,049 INFO <pdlog> dropna: dropped 1 row (17%), 5 rows remaining\n\nIt works by registering a custom LogAccessor under the .log namespace on import. The accessor containes a collection of wrapper methods that log what they’re doing."
  },
  {
    "objectID": "posts/doing-important-work.html",
    "href": "posts/doing-important-work.html",
    "title": "Doing important work",
    "section": "",
    "text": "I’ve been thinking a lot about what it means to Do Important Work, and there two quotes in particular that have stuck with me.\n\n\n\nAI-generated image of a labyrinth (source and prompt).\n\n\nThe first is from Visa’s The Prestige Trap. With his classic wit and charm, Visa breaks the problem down in the opening sentence:\n\nI’ve had several conversations with friends who’ve been incapacitated by the burdensome bullshit obligation to Have A Meaningful Life / Be Remembered / Do Important Work.\n\nAnd though the details differ, the second is a tweet from Michael Nielsen that I think is closely related:\n\nI try particularly to push back on the efficiency mindset with work (where it’s strongest). Asking “What’s a much more enjoyable way” to achieve some outcome (even if inefficient) has been very good for me. Amusingly, though not the point, it often makes the work much better too\n\nI think they’re very much speaking about the same thing. Many of us want to Do Important Work, including, in my opinion, Michael and Visa. That’s fine. A natural follow-up is to try to make it concrete with a question: What important work can I do?\nBut here’s the problem. Measuring the importance or meaning of an action is really hard. I’m not sure it’s even possible. From a pragmatic perspective, we might say that important work is recognised through reward, perhaps monetary. But, as Visa reminds us, ‘nobody really knows what the world needs! The world itself doesn’t quite know either, often until on hindsight!’.\nSo what do we do instead? Well, what seems to have worked empirically is to ‘enjoy the piddling’. To be playful and curious. To prefer the more enjoyable way. Feynman, Jobs, Wozniak, and Newton are all examples cited by Visa. It’s okay to want to Do Important Work. I think both Michael and Visakan really do want that. And I know I do. The trick is to rejig the way that you think about it away from the destructive default to a more constructive, and amusingly efficient alternative. I’m delighted by the similarity between Visa’s and Michael’s descriptions:\n\nVisa: Wonderfully, it seems to me that lots of people who end up Doing Important Work often got there by being playful and curious.\n\n\nMichael: Amusingly, though not the point, it often makes the work much better too.\n\nIt really is both wonderful and amusing. It feels like the gist of a koan: to Do Important Work, you must forget about Doing Important Work."
  },
  {
    "objectID": "posts/math-of-diffusion.html",
    "href": "posts/math-of-diffusion.html",
    "title": "Math of diffusion",
    "section": "",
    "text": "Check out Lesson 9B: Math of Diffusion of fast.ai’s Practical Deep Learning for Coders Part 2, 2022 from the wonderful Tanishq and myself if you want to understand the math of diffusion but feel intimidated by the jargon. You’ll learn about the key equations underpinning diffusion models, with no prerequisites beyond high school math."
  },
  {
    "objectID": "posts/math-of-diffusion.html#what-youll-learn",
    "href": "posts/math-of-diffusion.html#what-youll-learn",
    "title": "Math of diffusion",
    "section": "What you’ll learn",
    "text": "What you’ll learn\nWe walk through the math of diffusion models from the ground up, explaining the insights underlying the key equations in the work of Sohl-Dickstein et al. (2015) that originally discovered diffusion models.\nBy the end of the lesson you’ll have some understanding of the following key concepts and you’ll know how to recognize and interpret their symbols in research papers: probability density function (pdf), data distribution, forward process, reverse process, Markov process, Gaussian distribution, log likelihood, and evidence lower bound (ELBO).\nWe also touch on the more recent breakthroughs of Ho, Jain, and Abbeel (2020) which enabled even simpler and more powerful diffusion models.\nYou can discuss this lesson, and access links to all notebooks and resources from it, at this forum topic."
  },
  {
    "objectID": "posts/math-of-diffusion.html#you-dont-need-a-phd",
    "href": "posts/math-of-diffusion.html#you-dont-need-a-phd",
    "title": "Math of diffusion",
    "section": "You don’t need a PhD",
    "text": "You don’t need a PhD\nHere’s what Alex, a student of the course, had to say about the lesson:\n\n\n\n\n\nYou definitely don’t need a PhD! In fact, the lesson came about because I felt the same way as Alex. I was frustrated at how difficult I found it to understand the math in diffusion papers."
  },
  {
    "objectID": "posts/math-of-diffusion.html#recorded-at-fast.ai-hq",
    "href": "posts/math-of-diffusion.html#recorded-at-fast.ai-hq",
    "title": "Math of diffusion",
    "section": "Recorded at fast.ai HQ",
    "text": "Recorded at fast.ai HQ\nThanks to nudges from Jeremy, we went from an informal conversation, to a talk at the fast.ai unconference, to a recorded lesson – in a span of 4 days! Jeremy was kind enough to let us use his equipment and record at the fast.ai HQ."
  },
  {
    "objectID": "posts/math-of-diffusion.html#check-out-the-other-lesson-resources",
    "href": "posts/math-of-diffusion.html#check-out-the-other-lesson-resources",
    "title": "Math of diffusion",
    "section": "Check out the other lesson resources",
    "text": "Check out the other lesson resources\nI’m grateful to be part of this amazing group of people developing fast.ai’s From Deep Learning Foundations to Stable Diffusion. Follow the tweet below to find more lesson resources from the team: Johno Whitaker, Pedro Cuenca, Tanishq Abraham, and of course Jeremy Howard.\n\n\nI got a special surprise for you all…We just released the first 5.5 hours of our new course \"From Deep Learning Foundations to Stable Diffusion\", for free!https://t.co/LiUu9HSflG\n\n— Jeremy Howard ((jeremyphoward?)) October 20, 2022"
  },
  {
    "objectID": "tils/compiling-python-to-c-using-setuptools-and-cython.html",
    "href": "tils/compiling-python-to-c-using-setuptools-and-cython.html",
    "title": "Compiling Python to C using setuptools and Cython",
    "section": "",
    "text": "plum1 compiles an ordinary Python file into an extension module (in C) using Cython and setuptools’ Cython integration. It’s the first time I’ve encountered this, so here’s a high-level description of how it works.\nIn setup.py, pass the ext_modules arg to setup, wrapping an Extension that points to the module you want to compile:\n```python hl_lines=‘9’ from setuptools import setup, Extension\nsetup( # … ext_modules=[Extension(“plum.function”, [“plum/function.py”])], )"
  },
  {
    "objectID": "tils/compiling-python-to-c-using-setuptools-and-cython.html#whats-a-python-extension-module",
    "href": "tils/compiling-python-to-c-using-setuptools-and-cython.html#whats-a-python-extension-module",
    "title": "Compiling Python to C using setuptools and Cython",
    "section": "What’s a Python extension module?",
    "text": "What’s a Python extension module?\nAn extension module is a program written in C (or C++) that uses Python’s C API to hook into Python’s run-time system. Interop works both ways: you can call Python objects from C and vice versa. A common reason for using extensions is improved speed. See the official docs on extension modules for more."
  },
  {
    "objectID": "tils/compiling-python-to-c-using-setuptools-and-cython.html#whats-cython",
    "href": "tils/compiling-python-to-c-using-setuptools-and-cython.html#whats-cython",
    "title": "Compiling Python to C using setuptools and Cython",
    "section": "What’s Cython?",
    "text": "What’s Cython?\nCython is a compiler for compiling programs written in Python and the Cython programming language into C extension modules. I’d recommend the reading through the rather friendly documentation as well."
  },
  {
    "objectID": "tils/how-to-setup-a-gpu-instance-on-google-cloud-platform.html",
    "href": "tils/how-to-setup-a-gpu-instance-on-google-cloud-platform.html",
    "title": "How to setup a GPU notebook server on Google Cloud Platform (GCP)",
    "section": "",
    "text": "GCP is my current preferred cloud provider for GPU servers. I compared prices last year and found that GCP was the cheapest for lower-end GPUs. The notebook servers offered Vertex AI are very easy to setup. They come with PyTorch and NVIDIA/CUDA drivers already configured. I also prefer options that give me full control over the instance via an SSH connection from my terminal, which this does.\nDepending on when you’re reading this, these instructions may no longer be valid. Please let me know if that’s the case!"
  },
  {
    "objectID": "tils/how-to-setup-a-gpu-instance-on-google-cloud-platform.html#setup-a-gcp-account",
    "href": "tils/how-to-setup-a-gpu-instance-on-google-cloud-platform.html#setup-a-gcp-account",
    "title": "How to setup a GPU notebook server on Google Cloud Platform (GCP)",
    "section": "Setup a GCP account",
    "text": "Setup a GCP account\n\nCreate a GCP account here.\nRequest a GPU quota increase (follow the official instructions). This may take up to 48 hours.\nEnable the AI Platform via the left sidebar."
  },
  {
    "objectID": "tils/how-to-setup-a-gpu-instance-on-google-cloud-platform.html#create-a-notebook-instance-using-vertex-ai",
    "href": "tils/how-to-setup-a-gpu-instance-on-google-cloud-platform.html#create-a-notebook-instance-using-vertex-ai",
    "title": "How to setup a GPU notebook server on Google Cloud Platform (GCP)",
    "section": "Create a notebook instance using Vertex AI",
    "text": "Create a notebook instance using Vertex AI\n\nOpen the Vertex AI Workbench.\nClick New Notebook, PyTorch 1.12, then With 1 NVIDIA T4.\nSet your Notebook name.\nChoose a Region and Zone. I went with us-central1 and us-central-1b (which was the cheapest available at the time). Note that your choice of region and zone may affect GPU availability and does slightly affect pricing.\nBy default, you’ll be provided with an n1-standard-4 which has 4 vCPUs and 15 GB RAM, and an NVIDIA Tesla T4. If you need more resources, click the edit button next to Notebook properties, then Machine configuration, set your Machine type and GPU type, then click Create.\nCheck Install NVIDIA GPU driver automatically for me.\nWait a few seconds for the notebook server to spin up. Then click OPEN JUPYTERLAB.\n\n\n\n\n\n\n\nShutdown your server when you’re done working\n\n\n\nYou’ll be billed for as long as the server is running. You may also be billed a smaller amount for persistent storage even while the server is shutdown."
  },
  {
    "objectID": "tils/using-pelican-as-a-library.html",
    "href": "tils/using-pelican-as-a-library.html",
    "title": "Using Pelican as a library",
    "section": "",
    "text": "In this post you’ll learn how to use Pelican (a Python static site generator) programmatically rather than through its command-line interface. This will give you a better understanding of how Pelican works internally and enable you to customise it for your needs."
  },
  {
    "objectID": "tils/using-pelican-as-a-library.html#how-pelican-works",
    "href": "tils/using-pelican-as-a-library.html#how-pelican-works",
    "title": "Using Pelican as a library",
    "section": "How Pelican works",
    "text": "How Pelican works\nPelican’s highest-level of abstraction is its command-line interface, which you would typically use as follows:\n$ pelican content output -s pelicanconf.py\nThis would read all articles and pages in the content directory, convert them to HTML, render web pages with the relevant Jinja templates, and write the resulting static website to the output directory.\nThe rough flow to achieve this is as follows:\n\nInstantiate a list of Generators (which house all of the relevent Readers and a jinja Environment) and a Writer.\nFor each Generator:\n\nCall the generate_context method, which reads the input files, converts them to HTML, and adds the outputs to a context dictionary.\nCall the generate_output method, passing the Writer and context. This gets the relevant jinja Template from the Environment, renders it with the provided context, and writes the result to the final output directory.\n\n\nAs you can see, Generators are responsible for glueing together the lower-level components: Reader, jinja Template, and Writer. In order to understand each of these components, we’ll reimplement the core logic of a Generator from scratch!"
  },
  {
    "objectID": "tils/using-pelican-as-a-library.html#setup",
    "href": "tils/using-pelican-as-a-library.html#setup",
    "title": "Using Pelican as a library",
    "section": "Setup",
    "text": "Setup\nStart by setting root to the directory of your Pelican website. If you don’t yet have a website, follow Pelican’s informative documentation to get started:\n\nfrom pathlib import Path\n\nroot = Path('..')\n\nNow we can load our pelicanconf.py settings file. Pelican provides a function for this which handles details like applying defaults:\n\nfrom pelican.settings import read_settings\n\nsettings = read_settings(root/'pelicanconf.py')\n\nLet’s create a quick blog post for testing. I prefer to write more technical blog posts in Jupyter notebooks but we’ll use markdown here since Pelican supports it natively.\n\npost_filepath = root/'content/2022-06-20-hello-pelican.md'\n\n\n%%writefile {post_filepath}\nTitle: Hello Pelican\nSlug: hello-pelican\nAuthor: Wasim Lorgat\nDate: 2022-06-20\nTags: python, pelican\nCategory: python\n\n## Welcome\n\nHello and welcome to our markdown blog post!\n\nWriting ../content/2022-06-20-hello-pelican.md"
  },
  {
    "objectID": "tils/using-pelican-as-a-library.html#reader",
    "href": "tils/using-pelican-as-a-library.html#reader",
    "title": "Using Pelican as a library",
    "section": "Reader",
    "text": "Reader\nWe’ll start by instantiating a MarkdownReader to read our blog post. We’re using a MarkdownReader because we wrote the post in markdown, but Pelican also provides HTMLReader and RstReader if you prefer those formats.\n\nfrom pelican.readers import MarkdownReader\n\nreader = MarkdownReader(settings)\n\nThe most important part of a Reader is its read method which accepts a file path and returns the contents of the file in HTML format along with metadata about the file:\n\ncontent, metadata = reader.read(post_filepath)\n\n… content is a string containing the blog post content converted to HTML. Since this was written in a notebook, we can use an IPython function to render it directly!\n\nfrom IPython.core.display import HTML\nHTML(content)\n\nWelcome\nHello and welcome to our markdown blog post!\n\n\n… and metadata is a dictionary that describes the file:\n\nmetadata\n\n{'title': 'Hello Pelican',\n 'slug': 'hello-pelican',\n 'author': <Author 'Wasim Lorgat'>,\n 'date': SafeDatetime(2022, 6, 20, 0, 0),\n 'tags': [<Tag 'python'>, <Tag 'pelican'>],\n 'category': <Category 'python'>}"
  },
  {
    "objectID": "tils/using-pelican-as-a-library.html#writer",
    "href": "tils/using-pelican-as-a-library.html#writer",
    "title": "Using Pelican as a library",
    "section": "Writer",
    "text": "Writer\nNow that we have the contents of the post in HTML format, we’ll render it into a static web page using a Writer. However, we first need to create an appropriate jinja Template. Jinja provides the Environment class for reusing functionality across templates so we’ll use that here.\nPelican searches for templates in the following order:\n\nIndividual template overrides, via settings['THEME_TEMPLATES_OVERRIDES'].\nThe configured theme, via settings['THEME'].\nThe default simple theme packaged with Pelican.\n\nWe can implement this search order using a FileSystemLoader, housed in an Environment for convenience:\n\nimport pelican\nfrom jinja2 import Environment, FileSystemLoader\nfrom pathlib import Path\n\ntemplate_paths = [*(Path(o) for o in settings['THEME_TEMPLATES_OVERRIDES']),\n                  Path(settings['THEME'])/'templates',\n                  Path(pelican.__file__).parent/'themes/simple/templates']\nenv = Environment(loader=FileSystemLoader(template_paths),\n                  **settings['JINJA_ENVIRONMENT'])\n\nNow we can get the article template:\n\ntemplate = env.get_template('article.html')\n\nThe last step of preparation is to create the context dictionary that’s passed through to the Template to render the article:\n\nfrom pelican.contents import Article\n\ncontext = settings.copy()\narticle = Article(content, metadata, settings, post_filepath, context)\narticle.readtime = {'minutes': 1}  # NOTE: this is a workaround to support the readtime plugin that I use\ncontext['article'] = article\n\nAnd now we can write the final result!\n\nfrom pelican.writers import Writer\n\noutput_dir = root/'test'\nwriter = Writer(output_dir, settings)\nwriter.write_file(Path(post_filepath.name).with_suffix('.html'), template, context)\n\nLet’s read it back in and see what it looks like. We’ll extract only the body using a simple regex - I’d usually recommend considering Beautiful Soup for parsing HTML but regex works fine for our case:\n\nimport re\n\nwith open(output_dir/'2022-06-20-hello-pelican.html') as f: html = f.read()\nbody = re.findall('<body>(.*?)</body>', html, re.DOTALL)[0].strip()\nHTML(body)\n\n\n      \n        Wasim Lorgat\n      \n      Posts\n      TILs\n    \n\n\n\n  \n    Hello Pelican\n  \n\n\n\n  June 20, 2022 • 1 min read\n\n\nWelcome\nHello and welcome to our markdown blog post!\n\n\nThe provided templates have added a navigation bar at the top, a title below that, as well as the publication date and estimated reading time. And that’s it, we’ve successfully rendered a blog post web page using Pelican’s low-level components!\nBefore we end off, clean up the files we made along the way:\n\nimport shutil\nshutil.rmtree(output_dir, ignore_errors=True)\npost_filepath.unlink(missing_ok=True)"
  },
  {
    "objectID": "tils/setting-up-tils-in-pelican.html",
    "href": "tils/setting-up-tils-in-pelican.html",
    "title": "Setting up TILs in Pelican",
    "section": "",
    "text": "Inspired by Simon Willison, I started writing TILs (today I learned). I find it incredibly helpful to write as I code, but most of that writing has never left my private notebooks. TILs are my attempt at documenting and sharing my day-to-day learnings in case they might help others. The focus on learning also feels less daunting than writing blog posts.\nI wanted to support TILs on my blog as a separate set of posts with their own listing page. Thanks to Pelican’s incredible flexibility, this was quite easy!\nFollowing these steps requires using a custom theme. I personally use a custom theme (forked from the builtin simple theme) precisely so that I can easily make these sorts of customisations."
  },
  {
    "objectID": "tils/setting-up-tils-in-pelican.html#reconfigure-your-archives",
    "href": "tils/setting-up-tils-in-pelican.html#reconfigure-your-archives",
    "title": "Setting up TILs in Pelican",
    "section": "Reconfigure your archives",
    "text": "Reconfigure your archives\nStart by renaming archives.html to posts/index.html (relative to your theme’s templates directory).\nEdit the loop over dates in posts/index.html to exclude articles tagged til:\n{% for article in dates if 'til' not in article.tags|default([]) %}\nAdd the new path to DIRECT_TEMPLATES, the corresponding line of my pelicanconf.py now looks like:\nDIRECT_TEMPLATES = ['index', 'posts/index']\n… because I don’t have tag or category pages yet. Disable the original archives page:\nARCHIVES_SAVE_AS = ''\nIt should be working as it was before, but we’re now able to add a few more listings in the same way!"
  },
  {
    "objectID": "tils/setting-up-tils-in-pelican.html#create-the-tils-listing",
    "href": "tils/setting-up-tils-in-pelican.html#create-the-tils-listing",
    "title": "Setting up TILs in Pelican",
    "section": "Create the TILs listing",
    "text": "Create the TILs listing\nCopy posts/index.html to tils/index.html, and edit the for loop to only include articles tagged til (note that the not from before is missing):\n{% for article in dates if 'til' in article.tags|default([]) %}\nAdd the new path to DIRECT_TEMPLATES in your pelicanconf.py:\nDIRECT_TEMPLATES = ['index', 'posts/index', 'tils/index']\nYou probably also want to link to the listing from your nav bar. For my theme, that’s done by adding a line to the <nav> tag in my base.html template:\n<a href=\"{{ SITEURL }}/tils/\">TILs</a>"
  },
  {
    "objectID": "tils/setting-up-tils-in-pelican.html#hack-article-urls",
    "href": "tils/setting-up-tils-in-pelican.html#hack-article-urls",
    "title": "Setting up TILs in Pelican",
    "section": "Hack article URLs",
    "text": "Hack article URLs\nThis is my favourite part! At this point, you should have two working listings, but TIL article URLs will be the same as any other article. Pelican determines the URL and output location of an article by calling format with the article’s metadata on strings ARTICLE_URL and ARTICLE_SAVE_AS. That means we can implement a tiny string class with a custom format to dynamically set the URL of TILs to tils/{slug} and of posts to posts/{slug}!\nSimply include the following in your pelicanconf.py:\nclass ArticleUrl(str):\n    def format(self,tags=[],**kwargs): return ('tils/' if 'til' in tags else 'posts/') + super().format(**kwargs)\n\nARTICLE_URL = ArticleUrl('{slug}/')\nARTICLE_SAVE_AS = ArticleUrl('{slug}/index.html')"
  },
  {
    "objectID": "tils/setting-up-tils-in-pelican.html#update-invoke-task",
    "href": "tils/setting-up-tils-in-pelican.html#update-invoke-task",
    "title": "Setting up TILs in Pelican",
    "section": "Update invoke task",
    "text": "Update invoke task\nIf you’re using live reload via the invoke livereload task, you’ll need to update your task definition to include nested HTML files in your theme:\n-    server.watch('{}/templates/*.html'.format(theme_path), lambda: build(c))\n+    server.watch('{}/templates/**/*.html'.format(theme_path), lambda: build(c))"
  },
  {
    "objectID": "tils/index.html",
    "href": "tils/index.html",
    "title": "📖 TILs",
    "section": "",
    "text": "I find it incredibly helpful to write as I code, but most of that writing has never left my private notebooks. TILs (today I learneds) are my attempt at documenting and sharing my day-to-day learnings in case they might help others. The focus on learning also feels less daunting than writing blog posts.\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\nFeb 13, 2023\n\n\nCallbacks vs async/await\n\n\n\n\n\nJan 25, 2023\n\n\nHow to use NSTableView in SwiftUI\n\n\n\n\nJan 23, 2023\n\n\nHow to setup a GPU notebook server on Google Cloud Platform (GCP)\n\n\n\n\nDec 15, 2022\n\n\nHow to share terminal demos as razor-sharp animated SVG\n\n\n\n\nJul 10, 2022\n\n\nDiagnosing an issue with plugin modules, process pools, and the import system\n\n\n\n\nJul 8, 2022\n\n\nUpdate fastai union annotations using ast\n\n\n\n\nJul 4, 2022\n\n\nCompiling Python to C using setuptools and Cython\n\n\n\n\nJun 23, 2022\n\n\nPoint and click directory navigation inside a Jupyter notebook\n\n\n\n\nJun 23, 2022\n\n\nCreating a minimal custom Jupyter widget\n\n\n\n\nJun 22, 2022\n\n\nCreate and execute cells inside a Jupyter notebook\n\n\n\n\nJun 21, 2022\n\n\nSetting up TILs in Pelican\n\n\n\n\nJun 20, 2022\n\n\nUsing Pelican as a library\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tils/how-to-use-nstableview-in-swiftui.html",
    "href": "tils/how-to-use-nstableview-in-swiftui.html",
    "title": "How to use NSTableView in SwiftUI",
    "section": "",
    "text": "I recently started learning macOS development using SwiftUI as part of my latest project: building a macOS Jupyter frontend. While I’m loving Swift (the language) and SwiftUI (the UI framework), it’s sometimes extremely difficult to find out information that feels like it should be readily available.\nThe latest such case is how to use an NSTableView in SwiftUI. SwiftUI’s new List is great for iOS and multiplatform apps, but doesn’t seem to be designed for desktop-specific apps which can do with much more information-dense UIs.\nSwiftUI has the newer Table too, but it’s also quite limited at this stage. For example, I don’t think it’s possible to make an entire row clickable.\nThis left me wanting to try out the much more battle-tested NSTableView – but as an Apple dev noob, I couldn’t get a minimal example up and running after a few hours of tinkering!\n… So here’s a snippet you can copy paste.1 Keep reading below if you’d like to see how it works step-by-step.\nimport SwiftUI\n\nstruct TableView: NSViewRepresentable {\n    class Coordinator: NSObject, NSTableViewDelegate, NSTableViewDataSource {\n        let data = [\"Apple\", \"Banana\", \"Cherry\"]\n\n        func numberOfRows(in tableView: NSTableView) -> Int {\n            data.count\n        }\n\n        func tableView(_ tableView: NSTableView, viewFor tableColumn: NSTableColumn?, row: Int) -> NSView? {\n            NSTextField(labelWithString: data[row])\n        }\n    }\n\n    func makeCoordinator() -> Coordinator {\n        Coordinator()\n    }\n\n    func makeNSView(context: Context) -> NSTableView {\n        let tableView = NSTableView()\n        tableView.delegate = context.coordinator\n        tableView.dataSource = context.coordinator\n        tableView.addTableColumn(NSTableColumn())\n        return tableView\n    }\n\n    func updateNSView(_ nsView: NSTableView, context: Context) {\n        // Do nothing\n    }\n}\nStep-by-step:\nCreate your table view struct, conforming to NSViewRepresentable. This is a standard way of using AppKit/UIKit views in your SwiftUI applications.\nIn makeNSView, create the NSTableView with a single column, and leave updateNSView blank for now:\nstruct TableView: NSViewRepresentable {\n    func makeNSView(context: Context) -> NSTableView {\n        let tableView = NSTableView()\n        tableView.addColumn(NSTableColumn())\n        return tableView\n    }\n\n    func updateNSView(_ nsView: NSTableView, context: Context) {\n        // Do nothing\n    }\n}\nCreate a Coordinator, subclassing:\n\nNSTableViewDelegate which we’ll use to customize how cells are rendered as views, and\nNSTableViewDataSource to define the number of rows.\n\nImplement makeCoordinator, returning an instance of Coordinator, then link it to the table view in makeNSView:\nstruct TableView: NSViewRepresentable {\n    class Coordinator: NSObject, NSTableViewDelegate, NSTableViewDataSource {\n    }\n\n    func makeCoordinator() -> Coordinator {\n        Coordinator()\n    }\n\n    func makeNSView(context: Context) -> NSTableView {\n        let tableView = NSTableView()\n        tableView.delegate = context.coordinator\n        tableView.dataSource = context.coordinator\n        tableView.addColumn(NSTableColumn())\n        return tableView\n    }\n\n    func updateNSView(_ nsView: NSTableView, context: Context) {\n        // Do nothing\n    }\n}\nYou still won’t see anything being rendered yet, since we still need to implement NSTableViewDelegate and NSTableViewDataSource methods.\nFor this minimal example, we’ll use a simple static array of strings defined right in the coordinator, although in practice you would probably get data from the view.\nImplement NSTableViewDataSource’s numberOfRows and NSTableViewDelegate’s tableView(tableView:viewFor:row). The former returns the length of our array. The latter returns an NSTextField created from the corresponding row of data.\n    class Coordinator: NSObject, NSTableViewDelegate, NSTableViewDataSource {\n        let data = [\"Apple\", \"Banana\", \"Cherry\"]\n\n        func numberOfRows(in tableView: NSTableView) -> Int {\n            data.count\n        }\n\n        func tableView(_ tableView: NSTableView, viewFor tableColumn: NSTableColumn?, row: Int) -> NSView? {\n            NSTextField(labelWithString: data[row])\n        }\n    }\nThat’s it! This is the minimal implementation of an NSTableView in SwiftUI that I could find. Let me know on Twitter, via email, or via the GitHub discussion below if you have any comments or suggestions.\nHere are some next steps I have in mind:\n\nGet preview working (this looks helpful)\nCustom cell view\n\nVertically align text\n\nMultiple columns\n\nIndex column\nImage column\nDate column\n\nColumn headers\nMake it interactive\n\nDo something on select\nDo something on hover\nDo something on click\n\nLoad data dynamically\n\nLet me know if you’d find these helpful!\n\n\n\n\n\n\nFootnotes\n\n\nMany thanks to Alex Grebenyuk whose article and repo I heavily referenced to figure this out.↩︎"
  },
  {
    "objectID": "tils/update-fastai-union-annotations-using-ast.html",
    "href": "tils/update-fastai-union-annotations-using-ast.html",
    "title": "Update fastai union annotations using ast",
    "section": "",
    "text": "This notebook doesn’t render correctly until I figure out how to tell Quarto to echo code cells as is without parsing directives.\n\n\n\nThis notebook defines and exports a lightweight command line tool that updates union annotations in notebooks from the fastai tuple style (x:(int,str)) to the Python 3.10 union operator (x:int|str), using the ast standard library, and developed with nbdev.\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nimport ast\nimport sys\nfrom execnb.nbio import read_nb, write_nb\n:::\n\nfrom fastcore.test import test_eq\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef tuple2bitor(annot):\n    \"Convert fastai tuple style union annotation to py310 union operator\"\n    bitor = annot.dims[0]\n    for right in annot.dims[1:]: bitor = ast.BinOp(left=bitor, right=right, op=ast.BitOr())\n    return bitor\n\ndef tuple2bitorstr(annot): return ast.unparse(tuple2bitor(annot)).replace(' ', '')\n:::\n\na = ast.Tuple([ast.Name(id=o) for o in ('int','str','float')])\ntest_eq(ast.unparse(a),'(int, str, float)')\ntest_eq(tuple2bitorstr(a),'int|str|float')\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef split_parts(source, node):\n    \"Split `source` into parts before, containing, and after `node`\"\n    lines = source.split('\\n')\n    assert node.lineno == node.end_lineno, 'Multi-line annotations not supported'\n    l = node.lineno-1\n    line = lines[l]\n    s,e = node.col_offset, node.end_col_offset\n    return '\\n'.join(lines[:l]+[line[:s]]), line[s:e], '\\n'.join([line[e:]]+lines[l+1:])\n:::\n\ns = '''\ndef f(\n    x: (int, str, float),\n    y=5\n): pass'''\nn = ast.parse(s)\na = n.body[0].args.args[0].annotation\nps = split_parts(s, a)\ntest_eq(ps, ('\\ndef f(\\n    x: ', '(int, str, float)', ',\\n    y=5\\n): pass'))\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef replace_node(source, node, repl):\n    \"Replace `node` in `source` with `repl`\"\n    parts = split_parts(source, node)\n    return parts[0] + repl + parts[2]\n:::\n\ntest_eq(replace_node(s, a, tuple2bitorstr(a)), '\\ndef f(\\n    x: int|str|float,\\n    y=5\\n): pass')\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef fix_tuple_annots(source):\n    \"Convert all fastai tuple style union annotations in `source` to py310 union operator\"\n    while True:\n        n = ast.parse(source)\n        try: a = next(o.annotation for o in ast.walk(n) if isinstance(getattr(o,'annotation',None),ast.Tuple))\n        except StopIteration: return source\n        source = replace_node(source, a, tuple2bitorstr(a))\n:::\n\ns = '''\n@patch\ndef crop_pad(x:TensorBBox|TensorPoint|Image.Image,\n    sz:(int, tuple), # Crop/pad size of input, duplicated if one value is specified\n    tl:tuple=None, # Optional top-left coordinate of the crop/pad, if `None` center crop\n    orig_sz:tuple=None, # Original size of input\n    pad_mode:PadMode=PadMode.Zeros, # Fastai padding mode\n    resize_mode=BILINEAR, # Pillow `Image` resize mode\n    resize_to:tuple=None # Optional post crop/pad resize of input\n):\n    if isinstance(sz,int): sz = (sz,sz)\n    orig_sz = fastuple(_get_sz(x) if orig_sz is None else orig_sz)\n    sz,tl = fastuple(sz),fastuple(((_get_sz(x)-sz)//2) if tl is None else tl)\n    return x._do_crop_pad(sz, tl, orig_sz=orig_sz, pad_mode=pad_mode, resize_mode=resize_mode, resize_to=resize_to)\n'''\n\ntest_eq(fix_tuple_annots(s), '''\n@patch\ndef crop_pad(x:TensorBBox|TensorPoint|Image.Image,\n    sz:int|tuple, # Crop/pad size of input, duplicated if one value is specified\n    tl:tuple=None, # Optional top-left coordinate of the crop/pad, if `None` center crop\n    orig_sz:tuple=None, # Original size of input\n    pad_mode:PadMode=PadMode.Zeros, # Fastai padding mode\n    resize_mode=BILINEAR, # Pillow `Image` resize mode\n    resize_to:tuple=None # Optional post crop/pad resize of input\n):\n    if isinstance(sz,int): sz = (sz,sz)\n    orig_sz = fastuple(_get_sz(x) if orig_sz is None else orig_sz)\n    sz,tl = fastuple(sz),fastuple(((_get_sz(x)-sz)//2) if tl is None else tl)\n    return x._do_crop_pad(sz, tl, orig_sz=orig_sz, pad_mode=pad_mode, resize_mode=resize_mode, resize_to=resize_to)\n''')\n\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\ndef fix_nb_tuple_annots(nb):\n    \"Convert all fastai tuple style union annotations in `nb` to py310 union operator\"\n    for cell in nb.cells:\n        try: cell.source = fix_tuple_annots(cell.source)\n        except SyntaxError: pass\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’}\nfrom fastcore.script import *\nfrom fastcore.utils import *\n\n@call_parse\ndef main(fname:str): # A notebook name or glob to convert\n    \"Convert all fastai tuple style union annotations in `nb_path` to py310 union operators\"\n    for f in globtastic(fname, file_glob='*.ipynb', skip_folder_re='^[_.]'):\n        nb = read_nb(f)\n        fix_nb_tuple_annots(nb)\n        write_nb(nb, f)\n:::"
  },
  {
    "objectID": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html",
    "href": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html",
    "title": "Point and click directory navigation inside a Jupyter notebook",
    "section": "",
    "text": "Here’s a tiny demo of a point-and-click navigation interface with rich output powered by Jupyter notebooks and ipywidgets! I originally mentioned the idea in a previous TIL. I also tweeted about it which is the best place to leave any comments or questions if you’d like."
  },
  {
    "objectID": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html#tldr",
    "href": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html#tldr",
    "title": "Point and click directory navigation inside a Jupyter notebook",
    "section": "TL;DR",
    "text": "TL;DR\nIf all you need is a copy-pastable code snippet, here you go. Read on for a more in-depth description.\n\nfrom base64 import b64encode\nfrom functools import partial\nfrom IPython.display import Javascript, display\nfrom ipywidgets import Box, Button, Layout\nfrom pathlib import Path\n\ndef create_code_cell(code):\n    encoded_code = b64encode(code.encode()).decode()\n    display(Javascript(f\"\"\"\n        var code = IPython.notebook.insert_cell_below('code');\n        code.set_text(atob(\"{encoded_code}\"));\n        code.execute();\n        code.focus_cell()\"\"\"))\n\ndef on_click_dir(path, button): create_code_cell(f\"ls('{path}')\")\ndef on_click_file(path, button): create_code_cell(f\"Path('{path}')\")\n\ndef ls(root=Path()):\n    if isinstance(root, str): root = Path(root).expanduser()\n    paths = sorted(root.iterdir())\n    if not paths: return\n    button_layout = Layout(width='fit-content')\n    buttons = []\n    for path in paths:\n        button = Button(description=str(path.relative_to(root)), layout=button_layout)\n        button.on_click(partial(on_click_dir if path.is_dir() else on_click_file, path))\n        buttons.append(button)\n    box_layout = Layout(overflow='scroll hidden', height='500px', display='flex',\n                        flex_flow='column wrap', align_content='flex-start')\n    return Box(buttons, layout=box_layout)"
  },
  {
    "objectID": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html#minimal-implementation",
    "href": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html#minimal-implementation",
    "title": "Point and click directory navigation inside a Jupyter notebook",
    "section": "Minimal implementation",
    "text": "Minimal implementation\nWe start by defining a function to create and execute a code cell below the focused cell (see my previous TIL if you’d like more detail on this part):\n\ndef create_code_cell(code):\n    encoded_code = b64encode(code.encode()).decode()\n    display(Javascript(f\"\"\"\n        var code = IPython.notebook.insert_cell_below('code');\n        code.set_text(atob(\"{encoded_code}\"));\n        code.execute();\n        code.focus_cell()\n    \"\"\"))\n\nWe’re going to be using button widgets, which expect an on-click callback, so let’s define those next. The callback is expected to be a function accepting a single argument, button, to which the button object itself is passed - although we won’t be using it. We need to know the path that was clicked on as well, so we’ll have to partial that in later:\n\ndef on_click_dir(path, button): create_code_cell(f\"ls('{path}')\")\ndef on_click_file(path, button): create_code_cell(f\"Path('{path}')\")\n\nTest if it works:\n\non_click_file(Path('point-and-click-directory-navigation-inside-a-jupyter-notebook.ipynb'), None)\n\n\n\n\n\nPath('point-and-click-directory-navigation-inside-a-jupyter-notebook.ipynb')\n\nPosixPath('point-and-click-directory-navigation-inside-a-jupyter-notebook.ipynb')\n\n\nNeat! The cell above this was created by calling on_click_file.\nFinally, we implement a straightforward minimal ls function using Button widgets for Paths, and wrapping those in a VBox widget:\n\nfrom ipywidgets import VBox\n\ndef ls(root=Path()):\n    if isinstance(root, str): root = Path(root).expanduser()\n    paths = sorted(root.iterdir())\n    if not paths: return\n    buttons = []\n    for path in paths:\n        button = Button(description=str(path))\n        button.on_click(partial(on_click_dir if path.is_dir() else on_click_file, path))\n        buttons.append(button)\n    return VBox(buttons)"
  },
  {
    "objectID": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html#improved-styling",
    "href": "tils/point-and-click-directory-navigation-inside-a-jupyter-notebook.html#improved-styling",
    "title": "Point and click directory navigation inside a Jupyter notebook",
    "section": "Improved styling",
    "text": "Improved styling\nI don’t like how the implementation above is styled, so here is another with a few purely stylistic improvements:\n\ndef ls(root=Path()):\n    if isinstance(root, str): root = Path(root).expanduser()\n    paths = sorted(root.iterdir())\n    if not paths: return\n    button_layout = Layout(width='fit-content')\n    buttons = []\n    for path in paths:\n        button = Button(description=str(path.relative_to(root)), layout=button_layout)\n        button.on_click(partial(on_click_dir if path.is_dir() else on_click_file, path))\n        buttons.append(button)\n    box_layout = Layout(overflow='scroll hidden', height='500px', display='flex',\n                        flex_flow='column wrap', align_content='flex-start')\n    return Box(buttons, layout=box_layout)\n\n\nls('~/code/fastai')\n\n\n\n\nUnfortunately, my current blog setup doesn’t support widgets, but you should be able to run this locally. You can also check out the demo video in my tweet.\nIf you pay close attention to the demo video, you’ll notice that it’s still styled slightly differently to what we’ve built here. Some styles can’t be changed through ipywidget’s style interface, so that was achieved by manually writing CSS with the %%html magic command followed by a <style>...</style> tag, and then assigning a class to the buttons and boxes using their add_class method. I also implemented a custom widget with a small render JavaScript function that resized the output grid until it fit the width of the screen.\nI’m really excited with how this turned out! And it was far simpler than I’d expected. I’ll definitely be exploring the point-and-click navigation pattern more. I’m thinking about trying it out for exploring documentation about Python objects."
  },
  {
    "objectID": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html",
    "href": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html",
    "title": "Diagnosing an issue with plugin modules, process pools, and the import system",
    "section": "",
    "text": "This is a walkthrough of the rather surprising mechanics underlying a failing test that brings together plugin modules (that register themselves on import), process pools, and Python’s import system."
  },
  {
    "objectID": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#what-went-wrong",
    "href": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#what-went-wrong",
    "title": "Diagnosing an issue with plugin modules, process pools, and the import system",
    "section": "What went wrong",
    "text": "What went wrong\nIt starts with a failed test:\npat = r\"\\[\\d, \\d+.\\d+, \\d+.\\d+, \\d+.\\d+, '\\d\\d:\\d\\d'\\]\"\ntest_stdout(lambda: learn.fit(1), pat, regex=True)\nThe idea is to test that calling learn.fit(1) writes text to stdout (standard output) that matches the regex pattern pat. For those less familiar, this form of testing is common in projects that use nbdev.\nHere’s what actually happens:\n\nThe nbprocess_test command creates a ProcessPoolExecutor with some number of workers and tasks (each notebook being a separate task).\nWorker 1 processes one task, say task 1, which creates an IPython InteractiveShell, then runs import fastai.callbacks.progress which adds ProgressCallback to the the variable fastcore.basics.defaults.\nWorker 1 processes another task, say task 3, which creates a fresh InteractiveShell, calls learner.fit, and tests stdout. Since ProgressCallback has been registered in this process by task 1, a progress bar is also printed to stdout, breaking the test.\n\nLet’s break down the underlying mechanics. There are three behaviours that come together to cause this sequence of events:\n\nProcessPoolExecutors reuse processes. It seems obvious in hindsight since that’s how pools usually work, but I had never realised it until now. In the example above, worker 1 executes task 1 and task 3 in the same process.\nfastai callbacks register themselves on import. In this case, fastai.callbacks.progress adds ProgressCallback to defaults.callbacks.\nChanges to imported modules persist across IPython InteractiveShells. nbprocess_test runs each test in parallel using execnb, which implements a sub-class of InteractiveShell.\n\nNext, we’ll verify these behaviours with tiny experiments. I highly recommend using tiny experiments to understand complex systems."
  },
  {
    "objectID": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#processpoolexecutors-reuse-processes",
    "href": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#processpoolexecutors-reuse-processes",
    "title": "Diagnosing an issue with plugin modules, process pools, and the import system",
    "section": "ProcessPoolExecutors reuse processes",
    "text": "ProcessPoolExecutors reuse processes\nPerhaps we should know this simply from the name, but I didn’t, so we’ll figure it out with a tiny experiment. Start by creating a pool with 2 max_workers:\n\nfrom concurrent.futures import ProcessPoolExecutor\n\npool = ProcessPoolExecutor(max_workers=2)\n\nThere aren’t any processes in the pool yet:\n\npool._processes\n\n{}\n\n\nSubmit a task: the function os.getpid, which will return the process ID of the worker that runs it. Since there are no processes in the pool, submit will start a new worker process, and have it execute the task. ProcessPoolExecutor.submit returns a Future object, and Future.result returns the task’s return value:\n\nimport os\n\nfuture = pool.submit(os.getpid)\nfuture.result()\n\n45907\n\n\nNo matter how many times you manually rerun the above cell, it will aways be executed on the same process. Notice that the process is now also available in the pool:\n\npool._processes\n\n{45907: <SpawnProcess name='SpawnProcess-1' pid=45907 parent=45899 started>}\n\n\nIf we submit another task:\n\nfuture = pool.submit(os.getpid)\nfuture.result()\n\n45907\n\n\n…it’s still executed on the same process.\nLet’s try executing two processes at the same time:\n\nfutures = [pool.submit(os.getpid) for _ in range(2)]\n[o.result() for o in futures]\n\n[45907, 45907]\n\n\nWeird. They’re both executed on the same process…\n\npool._processes\n\n{45907: <SpawnProcess name='SpawnProcess-1' pid=45907 parent=45899 started>,\n 45908: <SpawnProcess name='SpawnProcess-2' pid=45908 parent=45899 started>}\n\n\nIt looks like another process was started! I haven’t confirmed this, but I suspect that when we submitted two futures, the pool determined that it needed more workers, so it started another. However, the first worker’s task ended before the second worker started up, so the first worker processed both.\nSince we instantiated the pool with 2 max_workers, these two processes will execute all tasks, no matter how many we submit:\n\nfutures = [pool.submit(os.getpid) for _ in range(10)]\n[o.result() for o in futures]\n\n[45907, 45907, 45907, 45907, 45907, 45907, 45907, 45907, 45907, 45907]\n\n\nShutdown the pool to free up any resources:\n\npool.shutdown()"
  },
  {
    "objectID": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#fastai-callbacks-register-themselves-on-import",
    "href": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#fastai-callbacks-register-themselves-on-import",
    "title": "Diagnosing an issue with plugin modules, process pools, and the import system",
    "section": "fastai callbacks register themselves on import",
    "text": "fastai callbacks register themselves on import\nThis one is easy to demonstrate. defaults has no callbacks attribute to start with:\n\nfrom fastcore.basics import defaults\n\ndefaults\n\nnamespace(cpus=4)\n\n\ndefaults.callbacks is populated after importing ProgressCallback:\n\nfrom fastai.callback.progress import ProgressCallback\n\ndefaults\n\nnamespace(cpus=4,\n          benchmark=True,\n          use_cuda=None,\n          activation=torch.nn.modules.activation.ReLU,\n          callbacks=[fastai.callback.core.TrainEvalCallback,\n                     fastai.learner.Recorder,\n                     fastai.learner.CastToTensor,\n                     fastai.callback.progress.ProgressCallback],\n          lr=0.001)"
  },
  {
    "objectID": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#changes-to-imported-modules-persist-across-ipython-interactiveshells",
    "href": "tils/diagnosing-an-issue-with-plugin-modules-process-pools-and-the-import-system.html#changes-to-imported-modules-persist-across-ipython-interactiveshells",
    "title": "Diagnosing an issue with plugin modules, process pools, and the import system",
    "section": "Changes to imported modules persist across IPython InteractiveShells",
    "text": "Changes to imported modules persist across IPython InteractiveShells\nWhy is any of the above a problem? Didn’t we say that nbprocess_test creates a separate shell for each notebook? Yes it does, but it turns out that changes to imported modules persist across shells.\n\nfrom execnb.shell import CaptureShell\n\nFirst make sure that CaptureShell doesn’t have a foo attribute - this will make sense in a second:\n\nassert not hasattr(CaptureShell, 'foo')\n\nNow add the foo attribute:\n\nCaptureShell.foo = 'bar'\n\nWe can see foo inside a CaptureShell:\n\nshell = CaptureShell()\nshell.run('from execnb.shell import CaptureShell; CaptureShell.foo')\nshell.result\n\n'bar'\n\n\nThis happens because when we first imported from the execnb.shell module it was cached in sys.modules:\n\nimport sys\n\nsys.modules['execnb.shell']\n\n<module 'execnb.shell' from '/Users/seem/code/execnb/execnb/shell.py'>\n\n\nIn fact, sys.modules['execnb.shell'].CaptureShell is another name for CaptureShell:\n\nsys.modules['execnb.shell'].CaptureShell is CaptureShell\n\nTrue\n\n\nPython caches imports to speed up consecutive imports from the same modules. InteractiveShell (and its sub-classes) have the same sys.modules which causes this behaviour:\n\nshell = CaptureShell()\nshell.run(\"import sys; sys.modules['execnb.shell'].CaptureShell.foo\")\nshell.result\n\n'bar'\n\n\nexec with empty globals and locals uses the same sys.modules too so it doesn’t avoid the issue:\n\nexec(\"import sys; print('execnb.shell' in sys.modules)\", {}, {})\n\nTrue\n\n\n\nexec(\"from execnb.shell import CaptureShell; print(CaptureShell.foo)\", {}, {})\n\nbar\n\n\n\nIn the end, we agreed that the test itself was broken, because it made assumptions about its environment without ensuring that they were true. Tests like this may fail - regardless of the above behaviour - if we import any module that registers a callback. For example, this fails too:\nfrom fastai.callback.progress import *\nfrom nbprocess.test import test_nb\n\ntest_nb('nbs/nb_with_failing_test.ipynb')\nThe fix is to explicitly run learner.fit with the precise list of callbacks required."
  },
  {
    "objectID": "tils/create-and-execute-cells-inside-a-jupyter-notebook.html",
    "href": "tils/create-and-execute-cells-inside-a-jupyter-notebook.html",
    "title": "Create and execute cells inside a Jupyter notebook",
    "section": "",
    "text": "I’ve been thinking a lot about unique Jupyter notebook interactions. A pattern that keeps coming up in my head is to click on the output of one cell to create a new cell below it. For example, ls() could output file and directory widgets for the current directory. Clicking on a directory widget, say foo, could create a code cell below with code ls(foo), to interactively browse through files.\n\n\n\n\n\n\nUpdate (2022-06-23)\n\n\n\nI’ve created a working demo of point-and-click directory navigation using this pattern!.\n\n\nI found this amazing gist by Fernando Perez (originally by Jonathan Frederic, see the gist for more links) which enables this pattern! It turns out that IPython makes this pretty straightforward. You directly execute JavaScript code against the IPython API that creates a code cell, sets the text of the cell (which must be base64 encoded), then executes it:\n\nimport base64\nfrom IPython.display import Javascript\nfrom ipywidgets import Button\n\ndef create_code_cell():\n    code = \"print('Hello world!')\"\n    encoded_code = base64.b64encode(code.encode()).decode()\n    display(Javascript(f'''\n        var code = IPython.notebook.insert_cell_below('code');\n        code.set_text(atob(\"{encoded_code}\"));\n        code.execute();\n    '''))\n\ncreate_code_cell()\n\n\n\n\n\nprint('Hello world!')\n\nHello world!\n\n\nI didn’t know that there was a neat JavaScript API inside Jupyter notebooks, but it does make sense that it exists. It’s also really useful to browse the API using your browser’s console via auto-complete on the IPython object:"
  },
  {
    "objectID": "tils/callbacks-vs-async-await.html",
    "href": "tils/callbacks-vs-async-await.html",
    "title": "Callbacks vs async/await",
    "section": "",
    "text": "import ipywidgets\nimport time\nfrom threading import Thread\n\nLet’s start with a very simple interface. An input text, a submit button, and an output text (disabled=True so that it’s not editable):\n\ninput_ = ipywidgets.Text(\"Hey ChatGPT, please summarise this text.\")\nbutton = ipywidgets.Button(description=\"Submit\")\noutput = ipywidgets.Text(disabled=True)\ndisplay(input_, button, output)\n\n\n\n\n\n\n\n\n\n\nThis won’t do anything yet. We need to setup an on_click callback first. We’ll fake a request to OpenAI that simply sleeps for half a second then returns a fixed string. Then we’ll update the output text’s value with the result:\n\ndef request_open_ai(prompt):\n    time.sleep(0.5)\n    return \"Here's a summary of your text.\"\n\n\ndef update_output(text):\n    output.value = text\n\n\ndef on_click(button):\n    text = request_open_ai(input_.value)\n    update_output(text)\n\n\nbutton.on_click(on_click)\n\nIf you click “Submit” now, it should populate the output after half a second.\nIf we do this synchronously and in the main thread, the entire UI will hang during the requestOpenAi call. So instead, we can separate that call into another thread. I think ipywidgets already does a version of this for us. But if it didn’t, here’s a very rough version of how we’d do it:\n\nThread(target=request_open_ai, args=(input,)).run()\n\nBut then how do we get the result and update the output with it? It’s often trickier to pass data across threads. Instead, we define our request function so that it accepts a callback that gets called with the result:\n\ndef request_open_ai(prompt, on_completion):\n    time.sleep(0.5)\n    on_completion(\"Here's a summary of your text.\")\n\n\ndef on_click(button):\n    Thread(target=request_open_ai, args=(input, update_output)).run()\n\n\ninput_ = ipywidgets.Text(\"Hey ChatGPT, please summarise this text.\")\nbutton = ipywidgets.Button(description=\"Submit\")\noutput = ipywidgets.Text(disabled=True)\nbutton.on_click(on_click)\ndisplay(input_, button, output)\n\n\n\n\n\n\n\n\n\n\nThis works okay, but starts to get very confusing as you add more and more nested callbacks. In fact, it can get so bad that it’s been nicknamed callback hell. Someone was so frustrated with it that they even created a website! This is where async/await becomes useful, since it looks a lot more like ordinary programming:\n\nimport asyncio\n\n\nasync def request_open_ai(prompt):\n    time.sleep(0.5)\n    return \"Here's a summary of your text.\"\n\n\nasync def on_click(button):\n    text = await request_open_ai(input_.value)\n    update_output(text)\n\nNote how these functions look a lot similar to the original synchronous ones instead of having the weird callbacks.\nIn most UI frameworks, we’d be able to pass in an async function like the new on_click. I’m not sure how to do that with ipywidgets, so we need to define a little wrapper that synchronously calls the async function, so we can set it as the button’s on_click handler (confusing, I know):\n\ndef on_click_sync(button):\n    coroutine = on_click(button)\n    asyncio.ensure_future(coroutine)\n\n\ninput_ = ipywidgets.Text(\"Hey ChatGPT, please summarise this text.\")\nbutton = ipywidgets.Button(description=\"Submit\")\noutput = ipywidgets.Text(disabled=True)\nbutton.on_click(on_click_sync)\ndisplay(input_, button, output)"
  },
  {
    "objectID": "tils/creating-a-minimal-custom-jupyter-widget.html",
    "href": "tils/creating-a-minimal-custom-jupyter-widget.html",
    "title": "Creating a minimal custom Jupyter widget",
    "section": "",
    "text": "I couldn’t find a super minimal example of implementing a custom Jupyter widget, so here it is. This is based on Pierre Marion’s Binder Repo for Hello World Jupyter Widget.\nimport ipywidgets as widgets\nfrom traitlets import Unicode, validate\n\n\nclass HelloWidget(widgets.DOMWidget):\n    _view_name = Unicode('HelloView').tag(sync=True)\n    _view_module = Unicode('hello').tag(sync=True)\n    _view_module_version = Unicode('0.1.0').tag(sync=True)\n    value = Unicode('Hello World!').tag(sync=True)\n%%javascript\nrequire.undef('hello');\n\ndefine('hello', [\"@jupyter-widgets/base\"], function(widgets) {\n\n    var HelloView = widgets.DOMWidgetView.extend({\n\n        render: function() { \n            this.el.textContent = this.model.get('value'); \n        },\n    });\n\n    return {\n        HelloView : HelloView\n    };\n});\nHelloWidget()"
  },
  {
    "objectID": "tils/creating-a-minimal-custom-jupyter-widget.html#further-reading",
    "href": "tils/creating-a-minimal-custom-jupyter-widget.html#further-reading",
    "title": "Creating a minimal custom Jupyter widget",
    "section": "Further reading",
    "text": "Further reading\nHere are some great articles that I referenced while exploring this topic:\n\nBinder Repo for Hello World Jupyter Widget\nAuthoring Custom Jupyter Widgets: A Hands-On Guide\nipywidgets Official Documentation: Building a Custom Widget - Email widget\nBinder Repo for Hello World Jupyter Widget\nIPython Notebook: Javascript/Python Bi-directional Communication. I think this may have been the birth of ipywidgets!"
  },
  {
    "objectID": "tils/how-to-share-terminal-demos-as-razor-sharp-animated-svg.html",
    "href": "tils/how-to-share-terminal-demos-as-razor-sharp-animated-svg.html",
    "title": "How to share terminal demos as razor-sharp animated SVG",
    "section": "",
    "text": "Install asciinema and svg-term-cli.\nRecord with asciinema:\nasciinema rec demo.cast\nThis records the session in the asciicast v2 plaintext file format (newline-delimited JSON with an initial header object followed by a timestamped event stream of stdin and stdout).\nConvert the .cast file to .svg with svg-term-cli:\nsvg-term --in demo.cast --out demo.svg --window --width 80 --height 22 --no-optimize\n\nYou probably want to play around with width and height\nwindow adds a fake OS window around the terminal session\nI found that no-optimize fixed some weird font rendering issues on my macOS – not sure why\n\n\n\nHere’s an example I created for my blog post Build a text editor with Python and curses:"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "💻 Projects",
    "section": "",
    "text": "My projects span machine learning, programming languages, personal analytics, browser extensions, code editors, and personal tools to support my workflows. I work on projects for fun, to learn, or to solve a specific problem I have. More recent projects are listed first.\nClick on a project’s heading to go to its website/repo."
  },
  {
    "objectID": "projects.html#section",
    "href": "projects.html#section",
    "title": "💻 Projects",
    "section": "2022",
    "text": "2022\n\nMeepo\nA smarter search engine for a local (South African) fashion and homeware store.\nI have no affiliation with said store. I built this for myself, because I was frustrated at how difficult it was to find what I wanted with the existing search engine + I was curious how well CLIP (a relatively new AI technique with open source code and models) would work here.\nI think it works quite well! It’s much more forgiving than the original search engine. I don’t have to guess what exactly they decided to label a particular item. But what I like even more is that it works quite well for abstract things like “colourful shoes”.\nHere’s the full stack:\n\nHardware: Deployed on a 2CPU 4GB RAM VPS with docker\nStorage: SQLite + object storage (for images)\nSearch: CLIP text/image neural networks + faiss similarity search index\nPipeline: Python scripts + cron\nWeb: Django serving HTML/Tailwind/daisyUI\nIDE: Developed in notebooks with nbdev\n\nI tried to keep the implementation as simple as possible and I’m happy with the result! It took ~2 weeks to build and has been running seamlessly without my input ever since.\nCheck out this Twitter thread for more details.\n\n\nnbdev\nI’m a core developer of nbdev, an open source notebook-driven software development platform.\nnbdev let’s me use exploratory programming (related to REPL-driven development and literate programming) for all of my software development.\nI also came up with the idea of hooking into the Jupyter file save API and using a custom git merge driver to improve Jupyter/git integration. All of the core functionality used by these hooks was already implemented by other nbdev core developers. You can find out more in the write-up.\n\n\nPlum dispatch for fastcore (experimental)\nAn experimental PR to fastcore (the core library powering the fastai deep learning framework), that replaces its custom type dispatch system with plum-dispatch. Both bring Julia’s multiple dispatch into Python using type annotations and decorators."
  },
  {
    "objectID": "projects.html#section-1",
    "href": "projects.html#section-1",
    "title": "💻 Projects",
    "section": "2021",
    "text": "2021\n\nEasyEquities browser extension\nA browser extension for the EasyEquities investment platform built with TypeScript, React, React Router, and Mock Service Worker (to develop against a mocked version of their API).\nThis started with frustration that EasyEquities didn’t provide a single view of my holdings across all of my investment accounts, nor of my time-weighted returns. I made good progress but stopped building this since there’s no public EasyEquities API, and sending handcrafted requests to the internal API of my investment platform seems like a bad idea!\n\n\nRepo links\nA tiny command-line tool to quickly open URLs related to your repos. I made this for a smoother experience while working on a manyrepo codebase.\n\n\nMyFitnessPal to SQLite\nSave your personal data from MyFitnessPal to a SQLite database. I occasionally use MyFitnessPal to track my weight and calories. Inspired by the dogsheep movement, I built this to afford personal analytics on my own data.\n\n\nCircleCI to SQLite\nSave your personal data from CircleCI to a SQLite database. I threw this together for a quick analysis on build times at a former workplace, which we could then follow up with easy build pipeline optimisations.\n\n\nReverse engineering ncode\nAn attempt at reverse engineering ncode paper technology. I got all the way down from what looked like dots on paper to a matrix which I needed to decode. Perhaps I’ll get back to it some day!\n\n\nRomulus\nAn experimental framework for creating structure-aware editors. The idea was that actions (e.g. move left, insert character) would be aware of the context surrounding the cursor location within the (tree-)structured document, thus would have slightly more intelligent behaviour.\nFor example, given a document ((foo)|, where | represents the cursor, and where ((foo)) is a known symbol represented some BlockRef object, inserting ) would know to create a BlockRef object in the internal tree structure. Like a hackier version of tree sitter. The vision was to use this framework to create a Roam clone using an enhanced markdown-like syntax for personal use.\n\n\nZip\nFunctional hierarchical zipper (tree cursor), with navigation, editing, and enumeration. A port of clojure.zip to JavaScript that I intended to use in Romulus.\n\n\nRoam tools\nTiny command-line tools for working with Roam graphs.\n\n\nRoam parser\nA tiny Roam parser built with Clojure and instaparse. I also live tweeted the entire development process.\n\n\nImage alignment\nKeypoint-based alignment of two grayscale images using ORB and RANSAC via skimage. This was completed as a take-home assignment for a job application, so I limited the implementation to a max of 8 hours."
  },
  {
    "objectID": "projects.html#section-2",
    "href": "projects.html#section-2",
    "title": "💻 Projects",
    "section": "2020",
    "text": "2020\n\nEditor\nMinimal terminal text editor written in Python and curses. I wrote a corresponding step-by-step tutorial as well.\n\n\nAdvent of Code\nI enjoyed taking part in AoC for years 2017, 2018, 2019, and 2020.\n\n\nAlfred Github local\nAn Alfred workflow to open GitHub repo URLs via a local workspace directory. No GitHub API access needed!\n\n\npdlog\nSeamless logging for pandas dataframe operations, inspired by tidylog. We used pandas in production extensively at a former workplace, and our code often ended up overwhelmed with logging logic. With pdlog it’s simple: instead of calling, say, df.dropna(), call df.log.dropna() and it’ll log <pdlog> dropna: dropped 1 row (17%), 5 rows remaining."
  },
  {
    "objectID": "projects.html#section-3",
    "href": "projects.html#section-3",
    "title": "💻 Projects",
    "section": "2018",
    "text": "2018\n\nNeural networks from scratch\nA basic implementation of neural networks from scratch. Shortly after my encounter with reinforcement learning (see below), I realised that deep learning was an important precursor and shifted my studies there.\n\n\nReinforcement learning from scratch\nRe-implementing sections of Sutton and Barto’s Reinforcement Learning: An Introduction. My first inspiration in AI was the possibility that a computer could play games better than the best humans! I was determined to build one of these AIs myself."
  }
]